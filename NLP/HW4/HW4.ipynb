{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "A3Q4odUxG6yl"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from unicodedata import normalize\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def load_file(path: str):\n",
    "    \"\"\" Loads the file into memory \"\"\"\n",
    "    with open(path, 'r', encoding='utf8') as fo:\n",
    "        content = fo.read()\n",
    "    return content\n",
    "\n",
    "def clean_data(content: str):\n",
    "    \"\"\" Cleans the data for tokenization \"\"\"\n",
    "    # Lowercase text and remove leading and ending newlines\n",
    "    text = content.lower().strip('\\n')\n",
    "    # Fix any encoding issues\n",
    "    text = normalize('NFD', text).encode('utf8')\n",
    "    text = text.decode('utf8')\n",
    "    # Match by paragraphs (at least two new lines)\n",
    "    par_match = re.compile(r'\\n{2,}')\n",
    "    lines = par_match.split(text)\n",
    "    cleaned = list()\n",
    "    for line in lines:\n",
    "        # Remove new line symbols\n",
    "        line = line.replace('\\n', ' ')\n",
    "        # Remove special characters and numbers\n",
    "        line = re.sub(\"[^a-z\\s\\']+\", \" \", line).replace(\"'\", \"\")\n",
    "        # Remove line with < 15 words\n",
    "        line = line.split()\n",
    "        if len(line) > 15:\n",
    "          # Remove whitespace\n",
    "          line = ' '.join(line)\n",
    "          cleaned.append(line)\n",
    "    return np.array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjxnAM4cMBd3",
    "outputId": "4dd27535-8273-48c4-b885-ad6a58259c3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with almost no restrictions whatsoever you may copy it give it away or re use it under the terms of the project gutenberg license included with this ebook or online at http www gutenberg org license if you are not located in the united states you ll have to check the laws of the country where you are located before using this ebook',\n",
       "        'part i book i the history of a family chapter i fyodor pavlovitch karamazov chapter ii he gets rid of his eldest son chapter iii the second marriage and the second family chapter iv the third son alyosha chapter v elders book ii an unfortunate gathering chapter i they arrive at the monastery chapter ii the old buffoon chapter iii peasant women who have faith chapter iv a lady of little faith chapter v so be it so be it chapter vi why is such a man alive chapter vii a young man bent on a career chapter viii the scandalous scene book iii the sensualists chapter i in the servants quarters chapter ii lizaveta chapter iii the confession of a passionate heart in verse chapter iv the confession of a passionate heart in anecdote chapter v the confession of a passionate heart heels up chapter vi smerdyakov chapter vii the controversy chapter viii over the brandy chapter ix the sensualists chapter x both together chapter xi another reputation ruined part ii book iv lacerations chapter i father ferapont chapter ii at his father s chapter iii a meeting with the schoolboys chapter iv at the hohlakovs chapter v a laceration in the drawing room chapter vi a laceration in the cottage chapter vii and in the open air book v pro and contra chapter i the engagement chapter ii smerdyakov with a guitar chapter iii the brothers make friends chapter iv rebellion chapter v the grand inquisitor chapter vi for awhile a very obscure one chapter vii it s always worth while speaking to a clever man book vi the russian monk chapter i father zossima and his visitors chapter ii the duel chapter iii conversations and exhortations of father zossima part iii book vii alyosha chapter i the breath of corruption chapter ii a critical moment chapter iii an onion chapter iv cana of galilee book viii mitya chapter i kuzma samsonov chapter ii lyagavy chapter iii gold mines chapter iv in the dark chapter v a sudden resolution chapter vi i am coming too chapter vii the first and rightful lover chapter viii delirium book ix the preliminary investigation chapter i the beginning of perhotin s official career chapter ii the alarm chapter iii the sufferings of a soul the first ordeal chapter iv the second ordeal chapter v the third ordeal chapter vi the prosecutor catches mitya chapter vii mitya s great secret received with hisses chapter viii the evidence of the witnesses the babe chapter ix they carry mitya away part iv book x the boys chapter i kolya krassotkin chapter ii children chapter iii the schoolboy chapter iv the lost dog chapter v by ilusha s bedside chapter vi precocity chapter vii ilusha book xi ivan chapter i at grushenka s chapter ii the injured foot chapter iii a little demon chapter iv a hymn and a secret chapter v not you not you chapter vi the first interview with smerdyakov chapter vii the second visit to smerdyakov chapter viii the third and last interview with smerdyakov chapter ix the devil ivan s nightmare chapter x it was he who said that book xii a judicial error chapter i the fatal day chapter ii dangerous witnesses chapter iii the medical experts and a pound of nuts chapter iv fortune smiles on mitya chapter v a sudden catastrophe chapter vi the prosecutor s speech sketches of character chapter vii an historical survey chapter viii a treatise on smerdyakov chapter ix the galloping troika the end of the prosecutor s speech chapter x the speech for the defense an argument that cuts both ways chapter xi there was no money there was no robbery chapter xii and there was no murder either chapter xiii a corrupter of thought chapter xiv the peasants stand firm epilogue chapter i plans for mitya s escape chapter ii for a moment the lie becomes truth chapter iii ilusha s funeral the speech at the stone footnotes',\n",
       "        'alexey fyodorovitch karamazov was the third son of fyodor pavlovitch karamazov a land owner well known in our district in his own day and still remembered among us owing to his gloomy and tragic death which happened thirteen years ago and which i shall describe in its proper place for the present i will only say that this landowner for so we used to call him although he hardly spent a day of his life on his own estate was a strange type yet one pretty frequently to be met with a type abject and vicious and at the same time senseless but he was one of those senseless persons who are very well capable of looking after their worldly affairs and apparently after nothing else fyodor pavlovitch for instance began with next to nothing his estate was of the smallest he ran to dine at other men s tables and fastened on them as a toady yet at his death it appeared that he had a hundred thousand roubles in hard cash at the same time he was all his life one of the most senseless fantastical fellows in the whole district i repeat it was not stupidity the majority of these fantastical fellows are shrewd and intelligent enough but just senselessness and a peculiar national form of it',\n",
       "        'he was married twice and had three sons the eldest dmitri by his first wife and two ivan and alexey by his second fyodor pavlovitch s first wife adelai da ivanovna belonged to a fairly rich and distinguished noble family also landowners in our district the miu sovs how it came to pass that an heiress who was also a beauty and moreover one of those vigorous intelligent girls so common in this generation but sometimes also to be found in the last could have married such a worthless puny weakling as we all called him i won t attempt to explain i knew a young lady of the last romantic generation who after some years of an enigmatic passion for a gentleman whom she might quite easily have married at any moment invented insuperable obstacles to their union and ended by throwing herself one stormy night into a rather deep and rapid river from a high bank almost a precipice and so perished entirely to satisfy her own caprice and to be like shakespeare s ophelia indeed if this precipice a chosen and favorite spot of hers had been less picturesque if there had been a prosaic flat bank in its place most likely the suicide would never have taken place this is a fact and probably there have been not a few similar instances in the last two or three generations adelai da ivanovna miu sov s action was similarly no doubt an echo of other people s ideas and was due to the irritation caused by lack of mental freedom she wanted perhaps to show her feminine independence to override class distinctions and the despotism of her family and a pliable imagination persuaded her we must suppose for a brief moment that fyodor pavlovitch in spite of his parasitic position was one of the bold and ironical spirits of that progressive epoch though he was in fact an ill natured buffoon and nothing more what gave the marriage piquancy was that it was preceded by an elopement and this greatly captivated adelai da ivanovna s fancy fyodor pavlovitch s position at the time made him specially eager for any such enterprise for he was passionately anxious to make a career in one way or another to attach himself to a good family and obtain a dowry was an alluring prospect as for mutual love it did not exist apparently either in the bride or in him in spite of adelai da ivanovna s beauty this was perhaps a unique case of the kind in the life of fyodor pavlovitch who was always of a voluptuous temper and ready to run after any petticoat on the slightest encouragement she seems to have been the only woman who made no particular appeal to his senses',\n",
       "        'immediately after the elopement adelai da ivanovna discerned in a flash that she had no feeling for her husband but contempt the marriage accordingly showed itself in its true colors with extraordinary rapidity although the family accepted the event pretty quickly and apportioned the runaway bride her dowry the husband and wife began to lead a most disorderly life and there were everlasting scenes between them it was said that the young wife showed incomparably more generosity and dignity than fyodor pavlovitch who as is now known got hold of all her money up to twenty five thousand roubles as soon as she received it so that those thousands were lost to her for ever the little village and the rather fine town house which formed part of her dowry he did his utmost for a long time to transfer to his name by means of some deed of conveyance he would probably have succeeded merely from her moral fatigue and desire to get rid of him and from the contempt and loathing he aroused by his persistent and shameless importunity but fortunately adelai da ivanovna s family intervened and circumvented his greediness it is known for a fact that frequent fights took place between the husband and wife but rumor had it that fyodor pavlovitch did not beat his wife but was beaten by her for she was a hot tempered bold dark browed impatient woman possessed of remarkable physical strength finally she left the house and ran away from fyodor pavlovitch with a destitute divinity student leaving mitya a child of three years old in her husband s hands immediately fyodor pavlovitch introduced a regular harem into the house and abandoned himself to orgies of drunkenness in the intervals he used to drive all over the province complaining tearfully to each and all of adelai da ivanovna s having left him going into details too disgraceful for a husband to mention in regard to his own married life what seemed to gratify him and flatter his self love most was to play the ridiculous part of the injured husband and to parade his woes with embellishments',\n",
       "        'one would think that you d got a promotion fyodor pavlovitch you seem so pleased in spite of your sorrow scoffers said to him many even added that he was glad of a new comic part in which to play the buffoon and that it was simply to make it funnier that he pretended to be unaware of his ludicrous position but who knows it may have been simplicity at last he succeeded in getting on the track of his runaway wife the poor woman turned out to be in petersburg where she had gone with her divinity student and where she had thrown herself into a life of complete emancipation fyodor pavlovitch at once began bustling about making preparations to go to petersburg with what object he could not himself have said he would perhaps have really gone but having determined to do so he felt at once entitled to fortify himself for the journey by another bout of reckless drinking and just at that time his wife s family received the news of her death in petersburg she had died quite suddenly in a garret according to one story of typhus or as another version had it of starvation fyodor pavlovitch was drunk when he heard of his wife s death and the story is that he ran out into the street and began shouting with joy raising his hands to heaven lord now lettest thou thy servant depart in peace but others say he wept without restraint like a little child so much so that people were sorry for him in spite of the repulsion he inspired it is quite possible that both versions were true that he rejoiced at his release and at the same time wept for her who released him as a general rule people even the wicked are much more nai ve and simple hearted than we suppose and we ourselves are too',\n",
       "        'you can easily imagine what a father such a man could be and how he would bring up his children his behavior as a father was exactly what might be expected he completely abandoned the child of his marriage with adelai da ivanovna not from malice nor because of his matrimonial grievances but simply because he forgot him while he was wearying every one with his tears and complaints and turning his house into a sink of debauchery a faithful servant of the family grigory took the three year old mitya into his care if he hadn t looked after him there would have been no one even to change the baby s little shirt',\n",
       "        'it happened moreover that the child s relations on his mother s side forgot him too at first his grandfather was no longer living his widow mitya s grandmother had moved to moscow and was seriously ill while his daughters were married so that mitya remained for almost a whole year in old grigory s charge and lived with him in the servant s cottage but if his father had remembered him he could not indeed have been altogether unaware of his existence he would have sent him back to the cottage as the child would only have been in the way of his debaucheries but a cousin of mitya s mother pyotr alexandrovitch miu sov happened to return from paris he lived for many years afterwards abroad but was at that time quite a young man and distinguished among the miu sovs as a man of enlightened ideas and of european culture who had been in the capitals and abroad towards the end of his life he became a liberal of the type common in the forties and fifties in the course of his career he had come into contact with many of the most liberal men of his epoch both in russia and abroad he had known proudhon and bakunin personally and in his declining years was very fond of describing the three days of the paris revolution of february hinting that he himself had almost taken part in the fighting on the barricades this was one of the most grateful recollections of his youth he had an independent property of about a thousand souls to reckon in the old style his splendid estate lay on the outskirts of our little town and bordered on the lands of our famous monastery with which pyotr alexandrovitch began an endless lawsuit almost as soon as he came into the estate concerning the rights of fishing in the river or wood cutting in the forest i don t know exactly which he regarded it as his duty as a citizen and a man of culture to open an attack upon the clericals hearing all about adelai da ivanovna whom he of course remembered and in whom he had at one time been interested and learning of the existence of mitya he intervened in spite of all his youthful indignation and contempt for fyodor pavlovitch he made the latter s acquaintance for the first time and told him directly that he wished to undertake the child s education he used long afterwards to tell as a characteristic touch that when he began to speak of mitya fyodor pavlovitch looked for some time as though he did not understand what child he was talking about and even as though he was surprised to hear that he had a little son in the house the story may have been exaggerated yet it must have been something like the truth',\n",
       "        'fyodor pavlovitch was all his life fond of acting of suddenly playing an unexpected part sometimes without any motive for doing so and even to his own direct disadvantage as for instance in the present case this habit however is characteristic of a very great number of people some of them very clever ones not like fyodor pavlovitch pyotr alexandrovitch carried the business through vigorously and was appointed with fyodor pavlovitch joint guardian of the child who had a small property a house and land left him by his mother mitya did in fact pass into this cousin s keeping but as the latter had no family of his own and after securing the revenues of his estates was in haste to return at once to paris he left the boy in charge of one of his cousins a lady living in moscow it came to pass that settling permanently in paris he too forgot the child especially when the revolution of february broke out making an impression on his mind that he remembered all the rest of his life the moscow lady died and mitya passed into the care of one of her married daughters i believe he changed his home a fourth time later on i won t enlarge upon that now as i shall have much to tell later of fyodor pavlovitch s firstborn and must confine myself now to the most essential facts about him without which i could not begin my story',\n",
       "        'in the first place this mitya or rather dmitri fyodorovitch was the only one of fyodor pavlovitch s three sons who grew up in the belief that he had property and that he would be independent on coming of age he spent an irregular boyhood and youth he did not finish his studies at the gymnasium he got into a military school then went to the caucasus was promoted fought a duel and was degraded to the ranks earned promotion again led a wild life and spent a good deal of money he did not begin to receive any income from fyodor pavlovitch until he came of age and until then got into debt he saw and knew his father fyodor pavlovitch for the first time on coming of age when he visited our neighborhood on purpose to settle with him about his property he seems not to have liked his father he did not stay long with him and made haste to get away having only succeeded in obtaining a sum of money and entering into an agreement for future payments from the estate of the revenues and value of which he was unable a fact worthy of note upon this occasion to get a statement from his father fyodor pavlovitch remarked for the first time then this too should be noted that mitya had a vague and exaggerated idea of his property fyodor pavlovitch was very well satisfied with this as it fell in with his own designs he gathered only that the young man was frivolous unruly of violent passions impatient and dissipated and that if he could only obtain ready money he would be satisfied although only of course for a short time so fyodor pavlovitch began to take advantage of this fact sending him from time to time small doles installments in the end when four years later mitya losing patience came a second time to our little town to settle up once for all with his father it turned out to his amazement that he had nothing that it was difficult to get an account even that he had received the whole value of his property in sums of money from fyodor pavlovitch and was perhaps even in debt to him that by various agreements into which he had of his own desire entered at various previous dates he had no right to expect anything more and so on and so on the young man was overwhelmed suspected deceit and cheating and was almost beside himself and indeed this circumstance led to the catastrophe the account of which forms the subject of my first introductory story or rather the external side of it but before i pass to that story i must say a little of fyodor pavlovitch s other two sons and of their origin'],\n",
       "       dtype='<U9487'),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fyodor = load_file('q1/28054-0.txt')\n",
    "f_data = clean_data(fyodor)\n",
    "f_labels = np.zeros(f_data.shape[0])\n",
    "f_data[0:10], f_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWYyykKGjNQi",
    "outputId": "b761e5e2-f3d7-4125-891f-f9ffdec25152"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or re use it under the terms of the project gutenberg license included with this ebook or online at www gutenberg net',\n",
       "        'i a scandal in bohemia ii the red headed league iii a case of identity iv the boscombe valley mystery v the five orange pips vi the man with the twisted lip vii the adventure of the blue carbuncle viii the adventure of the speckled band ix the adventure of the engineers thumb x the adventure of the noble bachelor xi the adventure of the beryl coronet xii the adventure of the copper beeches',\n",
       "        'to sherlock holmes she is always the woman i have seldom heard him mention her under any other name in his eyes she eclipses and predominates the whole of her sex it was not that he felt any emotion akin to love for irene adler all emotions and that one particularly were abhorrent to his cold precise but admirably balanced mind he was i take it the most perfect reasoning and observing machine that the world has seen but as a lover he would have placed himself in a false position he never spoke of the softer passions save with a gibe and a sneer they were admirable things for the observer excellent for drawing the veil from mens motives and actions but for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results grit in a sensitive instrument or a crack in one of his own high power lenses would not be more disturbing than a strong emotion in a nature such as his and yet there was but one woman to him and that woman was the late irene adler of dubious and questionable memory',\n",
       "        'i had seen little of holmes lately my marriage had drifted us away from each other my own complete happiness and the home centred interests which rise up around the man who first finds himself master of his own establishment were sufficient to absorb all my attention while holmes who loathed every form of society with his whole bohemian soul remained in our lodgings in baker street buried among his old books and alternating from week to week between cocaine and ambition the drowsiness of the drug and the fierce energy of his own keen nature he was still as ever deeply attracted by the study of crime and occupied his immense faculties and extraordinary powers of observation in following out those clues and clearing up those mysteries which had been abandoned as hopeless by the official police from time to time i heard some vague account of his doings of his summons to odessa in the case of the trepoff murder of his clearing up of the singular tragedy of the atkinson brothers at trincomalee and finally of the mission which he had accomplished so delicately and successfully for the reigning family of holland beyond these signs of his activity however which i merely shared with all the readers of the daily press i knew little of my former friend and companion',\n",
       "        'one night it was on the twentieth of march i was returning from a journey to a patient for i had now returned to civil practice when my way led me through baker street as i passed the well remembered door which must always be associated in my mind with my wooing and with the dark incidents of the study in scarlet i was seized with a keen desire to see holmes again and to know how he was employing his extraordinary powers his rooms were brilliantly lit and even as i looked up i saw his tall spare figure pass twice in a dark silhouette against the blind he was pacing the room swiftly eagerly with his head sunk upon his chest and his hands clasped behind him to me who knew his every mood and habit his attitude and manner told their own story he was at work again he had risen out of his drug created dreams and was hot upon the scent of some new problem i rang the bell and was shown up to the chamber which had formerly been in part my own',\n",
       "        'his manner was not effusive it seldom was but he was glad i think to see me with hardly a word spoken but with a kindly eye he waved me to an armchair threw across his case of cigars and indicated a spirit case and a gasogene in the corner then he stood before the fire and looked me over in his singular introspective fashion',\n",
       "        'wedlock suits you he remarked i think watson that you have put on seven and a half pounds since i saw you',\n",
       "        'indeed i should have thought a little more just a trifle more i fancy watson and in practice again i observe you did not tell me that you intended to go into harness',\n",
       "        'i see it i deduce it how do i know that you have been getting yourself very wet lately and that you have a most clumsy and careless servant girl',\n",
       "        'my dear holmes said i this is too much you would certainly have been burned had you lived a few centuries ago it is true that i had a country walk on thursday and came home in a dreadful mess but as i have changed my clothes i cant imagine how you deduce it as to mary jane she is incorrigible and my wife has given her notice but there again i fail to see how you work it out'],\n",
       "       dtype='<U2489'),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doyle = load_file('q1/pg1661.txt')\n",
    "d_data = clean_data(doyle)\n",
    "d_labels = np.ones(d_data.shape[0])\n",
    "d_data[0:10], d_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nrn59VrnjrW3",
    "outputId": "8e6fd3f3-a805-4347-d939-cbcd1d760dc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever you may copy it give it away or re use it under the terms of the project gutenberg license included with this ebook or online at www gutenberg org',\n",
       "        'note the accompanying html file has active links to all the volumes and chapters in this set',\n",
       "        'sir walter elliot of kellynch hall in somersetshire was a man who for his own amusement never took up any book but the baronetage there he found occupation for an idle hour and consolation in a distressed one there his faculties were roused into admiration and respect by contemplating the limited remnant of the earliest patents there any unwelcome sensations arising from domestic affairs changed naturally into pity and contempt as he turned over the almost endless creations of the last century and there if every other leaf were powerless he could read his own history with an interest which never failed this was the page at which the favourite volume always opened',\n",
       "        'walter elliot born march married july elizabeth daughter of james stevenson esq of south park in the county of gloucester by which lady who died he has issue elizabeth born june anne born august a still born son november mary born november',\n",
       "        'precisely such had the paragraph originally stood from the printers hands but sir walter had improved it by adding for the information of himself and his family these words after the date of marys birth married december charles son and heir of charles musgrove esq of uppercross in the county of somerset and by inserting most accurately the day of the month on which he had lost his wife',\n",
       "        'then followed the history and rise of the ancient and respectable family in the usual terms how it had been first settled in cheshire how mentioned in dugdale serving the office of high sheriff representing a borough in three successive parliaments exertions of loyalty and dignity of baronet in the first year of charles ii with all the marys and elizabeths they had married forming altogether two handsome duodecimo pages and concluding with the arms and motto principal seat kellynch hall in the county of somerset and sir walters handwriting again in this finale',\n",
       "        'vanity was the beginning and the end of sir walter elliots character vanity of person and of situation he had been remarkably handsome in his youth and at fifty four was still a very fine man few women could think more of their personal appearance than he did nor could the valet of any new made lord be more delighted with the place he held in society he considered the blessing of beauty as inferior only to the blessing of a baronetcy and the sir walter elliot who united these gifts was the constant object of his warmest respect and devotion',\n",
       "        'his good looks and his rank had one fair claim on his attachment since to them he must have owed a wife of very superior character to any thing deserved by his own lady elliot had been an excellent woman sensible and amiable whose judgement and conduct if they might be pardoned the youthful infatuation which made her lady elliot had never required indulgence afterwards she had humoured or softened or concealed his failings and promoted his real respectability for seventeen years and though not the very happiest being in the world herself had found enough in her duties her friends and her children to attach her to life and make it no matter of indifference to her when she was called on to quit them three girls the two eldest sixteen and fourteen was an awful legacy for a mother to bequeath an awful charge rather to confide to the authority and guidance of a conceited silly father she had however one very intimate friend a sensible deserving woman who had been brought by strong attachment to herself to settle close by her in the village of kellynch and on her kindness and advice lady elliot mainly relied for the best help and maintenance of the good principles and instruction which she had been anxiously giving her daughters',\n",
       "        'this friend and sir walter did not marry whatever might have been anticipated on that head by their acquaintance thirteen years had passed away since lady elliots death and they were still near neighbours and intimate friends and one remained a widower the other a widow',\n",
       "        'that lady russell of steady age and character and extremely well provided for should have no thought of a second marriage needs no apology to the public which is rather apt to be unreasonably discontented when a woman does marry again than when she does not but sir walters continuing in singleness requires explanation be it known then that sir walter like a good father having met with one or two private disappointments in very unreasonable applications prided himself on remaining single for his dear daughters sake for one daughter his eldest he would really have given up any thing which he had not been very much tempted to do elizabeth had succeeded at sixteen to all that was possible of her mothers rights and consequence and being very handsome and very like himself her influence had always been great and they had gone on together most happily his two other children were of very inferior value mary had acquired a little artificial importance by becoming mrs charles musgrove but anne with an elegance of mind and sweetness of character which must have placed her high with any people of real understanding was nobody with either father or sister her word had no weight her convenience was always to give way she was only anne',\n",
       "        'to lady russell indeed she was a most dear and highly valued god daughter favourite and friend lady russell loved them all but it was only in anne that she could fancy the mother to revive again',\n",
       "        'a few years before anne elliot had been a very pretty girl but her bloom had vanished early and as even in its height her father had found little to admire in her so totally different were her delicate features and mild dark eyes from his own there could be nothing in them now that she was faded and thin to excite his esteem he had never indulged much hope he had now none of ever reading her name in any other page of his favourite work all equality of alliance must rest with elizabeth for mary had merely connected herself with an old country family of respectability and large fortune and had therefore given all the honour and received none elizabeth would one day or other marry suitably',\n",
       "        'it sometimes happens that a woman is handsomer at twenty nine than she was ten years before and generally speaking if there has been neither ill health nor anxiety it is a time of life at which scarcely any charm is lost it was so with elizabeth still the same handsome miss elliot that she had begun to be thirteen years ago and sir walter might be excused therefore in forgetting her age or at least be deemed only half a fool for thinking himself and elizabeth as blooming as ever amidst the wreck of the good looks of everybody else for he could plainly see how old all the rest of his family and acquaintance were growing anne haggard mary coarse every face in the neighbourhood worsting and the rapid increase of the crows foot about lady russells temples had long been a distress to him',\n",
       "        'elizabeth did not quite equal her father in personal contentment thirteen years had seen her mistress of kellynch hall presiding and directing with a self possession and decision which could never have given the idea of her being younger than she was for thirteen years had she been doing the honours and laying down the domestic law at home and leading the way to the chaise and four and walking immediately after lady russell out of all the drawing rooms and dining rooms in the country thirteen winters revolving frosts had seen her opening every ball of credit which a scanty neighbourhood afforded and thirteen springs shewn their blossoms as she travelled up to london with her father for a few weeks annual enjoyment of the great world she had the remembrance of all this she had the consciousness of being nine and twenty to give her some regrets and some apprehensions she was fully satisfied of being still quite as handsome as ever but she felt her approach to the years of danger and would have rejoiced to be certain of being properly solicited by baronet blood within the next twelvemonth or two then might she again take up the book of books with as much enjoyment as in her early youth but now she liked it not always to be presented with the date of her own birth and see no marriage follow but that of a youngest sister made the book an evil and more than once when her father had left it open on the table near her had she closed it with averted eyes and pushed it away',\n",
       "        'she had had a disappointment moreover which that book and especially the history of her own family must ever present the remembrance of the heir presumptive the very william walter elliot esq whose rights had been so generously supported by her father had disappointed her',\n",
       "        'she had while a very young girl as soon as she had known him to be in the event of her having no brother the future baronet meant to marry him and her father had always meant that she should he had not been known to them as a boy but soon after lady elliots death sir walter had sought the acquaintance and though his overtures had not been met with any warmth he had persevered in seeking it making allowance for the modest drawing back of youth and in one of their spring excursions to london when elizabeth was in her first bloom mr elliot had been forced into the introduction',\n",
       "        'he was at that time a very young man just engaged in the study of the law and elizabeth found him extremely agreeable and every plan in his favour was confirmed he was invited to kellynch hall he was talked of and expected all the rest of the year but he never came the following spring he was seen again in town found equally agreeable again encouraged invited and expected and again he did not come and the next tidings were that he was married instead of pushing his fortune in the line marked out for the heir of the house of elliot he had purchased independence by uniting himself to a rich woman of inferior birth',\n",
       "        'sir walter has resented it as the head of the house he felt that he ought to have been consulted especially after taking the young man so publicly by the hand for they must have been seen together he observed once at tattersalls and twice in the lobby of the house of commons his disapprobation was expressed but apparently very little regarded mr elliot had attempted no apology and shewn himself as unsolicitous of being longer noticed by the family as sir walter considered him unworthy of it all acquaintance between them had ceased',\n",
       "        'this very awkward history of mr elliot was still after an interval of several years felt with anger by elizabeth who had liked the man for himself and still more for being her fathers heir and whose strong family pride could see only in him a proper match for sir walter elliots eldest daughter there was not a baronet from a to z whom her feelings could have so willingly acknowledged as an equal yet so miserably had he conducted himself that though she was at this present time the summer of wearing black ribbons for his wife she could not admit him to be worth thinking of again the disgrace of his first marriage might perhaps as there was no reason to suppose it perpetuated by offspring have been got over had he not done worse but he had as by the accustomary intervention of kind friends they had been informed spoken most disrespectfully of them all most slightingly and contemptuously of the very blood he belonged to and the honours which were hereafter to be his own this could not be pardoned',\n",
       "        'such were elizabeth elliots sentiments and sensations such the cares to alloy the agitations to vary the sameness and the elegance the prosperity and the nothingness of her scene of life such the feelings to give interest to a long uneventful residence in one country circle to fill the vacancies which there were no habits of utility abroad no talents or accomplishments for home to occupy'],\n",
       "       dtype='<U14176'),\n",
       " array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "        2., 2., 2.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "austen = load_file('q1/pg31100.txt')\n",
    "a_data = clean_data(austen)\n",
    "a_labels = np.ones(a_data.shape[0]) + 1\n",
    "a_data[0:20], a_labels[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8j0fIJ6-kOOu",
    "outputId": "e2e7ed3c-def9-48a2-a29d-160688a50dd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with almost no restrictions whatsoever you may copy it give it away or re use it under the terms of the project gutenberg license included with this ebook or online at http www gutenberg org license if you are not located in the united states you ll have to check the laws of the country where you are located before using this ebook',\n",
       "        'part i book i the history of a family chapter i fyodor pavlovitch karamazov chapter ii he gets rid of his eldest son chapter iii the second marriage and the second family chapter iv the third son alyosha chapter v elders book ii an unfortunate gathering chapter i they arrive at the monastery chapter ii the old buffoon chapter iii peasant women who have faith chapter iv a lady of little faith chapter v so be it so be it chapter vi why is such a man alive chapter vii a young man bent on a career chapter viii the scandalous scene book iii the sensualists chapter i in the servants quarters chapter ii lizaveta chapter iii the confession of a passionate heart in verse chapter iv the confession of a passionate heart in anecdote chapter v the confession of a passionate heart heels up chapter vi smerdyakov chapter vii the controversy chapter viii over the brandy chapter ix the sensualists chapter x both together chapter xi another reputation ruined part ii book iv lacerations chapter i father ferapont chapter ii at his father s chapter iii a meeting with the schoolboys chapter iv at the hohlakovs chapter v a laceration in the drawing room chapter vi a laceration in the cottage chapter vii and in the open air book v pro and contra chapter i the engagement chapter ii smerdyakov with a guitar chapter iii the brothers make friends chapter iv rebellion chapter v the grand inquisitor chapter vi for awhile a very obscure one chapter vii it s always worth while speaking to a clever man book vi the russian monk chapter i father zossima and his visitors chapter ii the duel chapter iii conversations and exhortations of father zossima part iii book vii alyosha chapter i the breath of corruption chapter ii a critical moment chapter iii an onion chapter iv cana of galilee book viii mitya chapter i kuzma samsonov chapter ii lyagavy chapter iii gold mines chapter iv in the dark chapter v a sudden resolution chapter vi i am coming too chapter vii the first and rightful lover chapter viii delirium book ix the preliminary investigation chapter i the beginning of perhotin s official career chapter ii the alarm chapter iii the sufferings of a soul the first ordeal chapter iv the second ordeal chapter v the third ordeal chapter vi the prosecutor catches mitya chapter vii mitya s great secret received with hisses chapter viii the evidence of the witnesses the babe chapter ix they carry mitya away part iv book x the boys chapter i kolya krassotkin chapter ii children chapter iii the schoolboy chapter iv the lost dog chapter v by ilusha s bedside chapter vi precocity chapter vii ilusha book xi ivan chapter i at grushenka s chapter ii the injured foot chapter iii a little demon chapter iv a hymn and a secret chapter v not you not you chapter vi the first interview with smerdyakov chapter vii the second visit to smerdyakov chapter viii the third and last interview with smerdyakov chapter ix the devil ivan s nightmare chapter x it was he who said that book xii a judicial error chapter i the fatal day chapter ii dangerous witnesses chapter iii the medical experts and a pound of nuts chapter iv fortune smiles on mitya chapter v a sudden catastrophe chapter vi the prosecutor s speech sketches of character chapter vii an historical survey chapter viii a treatise on smerdyakov chapter ix the galloping troika the end of the prosecutor s speech chapter x the speech for the defense an argument that cuts both ways chapter xi there was no money there was no robbery chapter xii and there was no murder either chapter xiii a corrupter of thought chapter xiv the peasants stand firm epilogue chapter i plans for mitya s escape chapter ii for a moment the lie becomes truth chapter iii ilusha s funeral the speech at the stone footnotes',\n",
       "        'alexey fyodorovitch karamazov was the third son of fyodor pavlovitch karamazov a land owner well known in our district in his own day and still remembered among us owing to his gloomy and tragic death which happened thirteen years ago and which i shall describe in its proper place for the present i will only say that this landowner for so we used to call him although he hardly spent a day of his life on his own estate was a strange type yet one pretty frequently to be met with a type abject and vicious and at the same time senseless but he was one of those senseless persons who are very well capable of looking after their worldly affairs and apparently after nothing else fyodor pavlovitch for instance began with next to nothing his estate was of the smallest he ran to dine at other men s tables and fastened on them as a toady yet at his death it appeared that he had a hundred thousand roubles in hard cash at the same time he was all his life one of the most senseless fantastical fellows in the whole district i repeat it was not stupidity the majority of these fantastical fellows are shrewd and intelligent enough but just senselessness and a peculiar national form of it',\n",
       "        'he was married twice and had three sons the eldest dmitri by his first wife and two ivan and alexey by his second fyodor pavlovitch s first wife adelai da ivanovna belonged to a fairly rich and distinguished noble family also landowners in our district the miu sovs how it came to pass that an heiress who was also a beauty and moreover one of those vigorous intelligent girls so common in this generation but sometimes also to be found in the last could have married such a worthless puny weakling as we all called him i won t attempt to explain i knew a young lady of the last romantic generation who after some years of an enigmatic passion for a gentleman whom she might quite easily have married at any moment invented insuperable obstacles to their union and ended by throwing herself one stormy night into a rather deep and rapid river from a high bank almost a precipice and so perished entirely to satisfy her own caprice and to be like shakespeare s ophelia indeed if this precipice a chosen and favorite spot of hers had been less picturesque if there had been a prosaic flat bank in its place most likely the suicide would never have taken place this is a fact and probably there have been not a few similar instances in the last two or three generations adelai da ivanovna miu sov s action was similarly no doubt an echo of other people s ideas and was due to the irritation caused by lack of mental freedom she wanted perhaps to show her feminine independence to override class distinctions and the despotism of her family and a pliable imagination persuaded her we must suppose for a brief moment that fyodor pavlovitch in spite of his parasitic position was one of the bold and ironical spirits of that progressive epoch though he was in fact an ill natured buffoon and nothing more what gave the marriage piquancy was that it was preceded by an elopement and this greatly captivated adelai da ivanovna s fancy fyodor pavlovitch s position at the time made him specially eager for any such enterprise for he was passionately anxious to make a career in one way or another to attach himself to a good family and obtain a dowry was an alluring prospect as for mutual love it did not exist apparently either in the bride or in him in spite of adelai da ivanovna s beauty this was perhaps a unique case of the kind in the life of fyodor pavlovitch who was always of a voluptuous temper and ready to run after any petticoat on the slightest encouragement she seems to have been the only woman who made no particular appeal to his senses',\n",
       "        'immediately after the elopement adelai da ivanovna discerned in a flash that she had no feeling for her husband but contempt the marriage accordingly showed itself in its true colors with extraordinary rapidity although the family accepted the event pretty quickly and apportioned the runaway bride her dowry the husband and wife began to lead a most disorderly life and there were everlasting scenes between them it was said that the young wife showed incomparably more generosity and dignity than fyodor pavlovitch who as is now known got hold of all her money up to twenty five thousand roubles as soon as she received it so that those thousands were lost to her for ever the little village and the rather fine town house which formed part of her dowry he did his utmost for a long time to transfer to his name by means of some deed of conveyance he would probably have succeeded merely from her moral fatigue and desire to get rid of him and from the contempt and loathing he aroused by his persistent and shameless importunity but fortunately adelai da ivanovna s family intervened and circumvented his greediness it is known for a fact that frequent fights took place between the husband and wife but rumor had it that fyodor pavlovitch did not beat his wife but was beaten by her for she was a hot tempered bold dark browed impatient woman possessed of remarkable physical strength finally she left the house and ran away from fyodor pavlovitch with a destitute divinity student leaving mitya a child of three years old in her husband s hands immediately fyodor pavlovitch introduced a regular harem into the house and abandoned himself to orgies of drunkenness in the intervals he used to drive all over the province complaining tearfully to each and all of adelai da ivanovna s having left him going into details too disgraceful for a husband to mention in regard to his own married life what seemed to gratify him and flatter his self love most was to play the ridiculous part of the injured husband and to parade his woes with embellishments',\n",
       "        'one would think that you d got a promotion fyodor pavlovitch you seem so pleased in spite of your sorrow scoffers said to him many even added that he was glad of a new comic part in which to play the buffoon and that it was simply to make it funnier that he pretended to be unaware of his ludicrous position but who knows it may have been simplicity at last he succeeded in getting on the track of his runaway wife the poor woman turned out to be in petersburg where she had gone with her divinity student and where she had thrown herself into a life of complete emancipation fyodor pavlovitch at once began bustling about making preparations to go to petersburg with what object he could not himself have said he would perhaps have really gone but having determined to do so he felt at once entitled to fortify himself for the journey by another bout of reckless drinking and just at that time his wife s family received the news of her death in petersburg she had died quite suddenly in a garret according to one story of typhus or as another version had it of starvation fyodor pavlovitch was drunk when he heard of his wife s death and the story is that he ran out into the street and began shouting with joy raising his hands to heaven lord now lettest thou thy servant depart in peace but others say he wept without restraint like a little child so much so that people were sorry for him in spite of the repulsion he inspired it is quite possible that both versions were true that he rejoiced at his release and at the same time wept for her who released him as a general rule people even the wicked are much more nai ve and simple hearted than we suppose and we ourselves are too',\n",
       "        'you can easily imagine what a father such a man could be and how he would bring up his children his behavior as a father was exactly what might be expected he completely abandoned the child of his marriage with adelai da ivanovna not from malice nor because of his matrimonial grievances but simply because he forgot him while he was wearying every one with his tears and complaints and turning his house into a sink of debauchery a faithful servant of the family grigory took the three year old mitya into his care if he hadn t looked after him there would have been no one even to change the baby s little shirt',\n",
       "        'it happened moreover that the child s relations on his mother s side forgot him too at first his grandfather was no longer living his widow mitya s grandmother had moved to moscow and was seriously ill while his daughters were married so that mitya remained for almost a whole year in old grigory s charge and lived with him in the servant s cottage but if his father had remembered him he could not indeed have been altogether unaware of his existence he would have sent him back to the cottage as the child would only have been in the way of his debaucheries but a cousin of mitya s mother pyotr alexandrovitch miu sov happened to return from paris he lived for many years afterwards abroad but was at that time quite a young man and distinguished among the miu sovs as a man of enlightened ideas and of european culture who had been in the capitals and abroad towards the end of his life he became a liberal of the type common in the forties and fifties in the course of his career he had come into contact with many of the most liberal men of his epoch both in russia and abroad he had known proudhon and bakunin personally and in his declining years was very fond of describing the three days of the paris revolution of february hinting that he himself had almost taken part in the fighting on the barricades this was one of the most grateful recollections of his youth he had an independent property of about a thousand souls to reckon in the old style his splendid estate lay on the outskirts of our little town and bordered on the lands of our famous monastery with which pyotr alexandrovitch began an endless lawsuit almost as soon as he came into the estate concerning the rights of fishing in the river or wood cutting in the forest i don t know exactly which he regarded it as his duty as a citizen and a man of culture to open an attack upon the clericals hearing all about adelai da ivanovna whom he of course remembered and in whom he had at one time been interested and learning of the existence of mitya he intervened in spite of all his youthful indignation and contempt for fyodor pavlovitch he made the latter s acquaintance for the first time and told him directly that he wished to undertake the child s education he used long afterwards to tell as a characteristic touch that when he began to speak of mitya fyodor pavlovitch looked for some time as though he did not understand what child he was talking about and even as though he was surprised to hear that he had a little son in the house the story may have been exaggerated yet it must have been something like the truth',\n",
       "        'fyodor pavlovitch was all his life fond of acting of suddenly playing an unexpected part sometimes without any motive for doing so and even to his own direct disadvantage as for instance in the present case this habit however is characteristic of a very great number of people some of them very clever ones not like fyodor pavlovitch pyotr alexandrovitch carried the business through vigorously and was appointed with fyodor pavlovitch joint guardian of the child who had a small property a house and land left him by his mother mitya did in fact pass into this cousin s keeping but as the latter had no family of his own and after securing the revenues of his estates was in haste to return at once to paris he left the boy in charge of one of his cousins a lady living in moscow it came to pass that settling permanently in paris he too forgot the child especially when the revolution of february broke out making an impression on his mind that he remembered all the rest of his life the moscow lady died and mitya passed into the care of one of her married daughters i believe he changed his home a fourth time later on i won t enlarge upon that now as i shall have much to tell later of fyodor pavlovitch s firstborn and must confine myself now to the most essential facts about him without which i could not begin my story',\n",
       "        'in the first place this mitya or rather dmitri fyodorovitch was the only one of fyodor pavlovitch s three sons who grew up in the belief that he had property and that he would be independent on coming of age he spent an irregular boyhood and youth he did not finish his studies at the gymnasium he got into a military school then went to the caucasus was promoted fought a duel and was degraded to the ranks earned promotion again led a wild life and spent a good deal of money he did not begin to receive any income from fyodor pavlovitch until he came of age and until then got into debt he saw and knew his father fyodor pavlovitch for the first time on coming of age when he visited our neighborhood on purpose to settle with him about his property he seems not to have liked his father he did not stay long with him and made haste to get away having only succeeded in obtaining a sum of money and entering into an agreement for future payments from the estate of the revenues and value of which he was unable a fact worthy of note upon this occasion to get a statement from his father fyodor pavlovitch remarked for the first time then this too should be noted that mitya had a vague and exaggerated idea of his property fyodor pavlovitch was very well satisfied with this as it fell in with his own designs he gathered only that the young man was frivolous unruly of violent passions impatient and dissipated and that if he could only obtain ready money he would be satisfied although only of course for a short time so fyodor pavlovitch began to take advantage of this fact sending him from time to time small doles installments in the end when four years later mitya losing patience came a second time to our little town to settle up once for all with his father it turned out to his amazement that he had nothing that it was difficult to get an account even that he had received the whole value of his property in sums of money from fyodor pavlovitch and was perhaps even in debt to him that by various agreements into which he had of his own desire entered at various previous dates he had no right to expect anything more and so on and so on the young man was overwhelmed suspected deceit and cheating and was almost beside himself and indeed this circumstance led to the catastrophe the account of which forms the subject of my first introductory story or rather the external side of it but before i pass to that story i must say a little of fyodor pavlovitch s other two sons and of their origin'],\n",
       "       dtype='<U14176'),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.hstack((f_data, d_data))\n",
    "data = np.hstack((data, a_data))\n",
    "\n",
    "n = f_data.shape[0] + d_data.shape[0] + a_data.shape[0]\n",
    "assert data.shape[0] == n\n",
    "\n",
    "labels = np.hstack((f_labels, d_labels))\n",
    "labels = np.hstack((labels, a_labels))\n",
    "\n",
    "assert labels.shape[0] == n\n",
    "data[0:10], labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ehDSGzojw_p7",
    "outputId": "0e33c46a-e21b-47dd-8b2e-aa7a6204cf73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14068, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "assert labels.shape[0] == n\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xaKekjHplYgw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['you ll be too much ashamed if you confess it all and what s more it will be no use at all for i shall say straight out that i never said anything of the sort to you and that you are either ill and it looks like it too or that you re so sorry for your brother that you are sacrificing yourself to save him and have invented it all against me for you ve always thought no more of me than if i d been a fly and who will believe you and what single proof have you got',\n",
       "       'though edmund was much more displeased with his aunt than with his mother as evincing least regard for her niece he could not help paying more attention to what she said and at length determined on a method of proceeding which would obviate the risk of his fathers thinking he had done too much and at the same time procure for fanny the immediate means of exercise which he could not bear she should be without he had three horses of his own but not one that would carry a woman two of them were hunters the third a useful road horse this third he resolved to exchange for one that his cousin might ride he knew where such a one was to be met with and having once made up his mind the whole business was soon completed the new mare proved a treasure with a very little trouble she became exactly calculated for the purpose and fanny was then put in almost full possession of her she had not supposed before that anything could ever suit her like the old grey pony but her delight in edmunds mare was far beyond any former pleasure of the sort and the addition it was ever receiving in the consideration of that kindness from which her pleasure sprung was beyond all her words to express she regarded her cousin as an example of everything good and great as possessing worth which no one but herself could ever appreciate and as entitled to such gratitude from her as no feelings could be strong enough to pay her sentiments towards him were compounded of all that was respectful grateful confiding and tender',\n",
       "       'i am sorry for miss crawford but i am more sorry to see you drawn in to do what you had resolved against and what you are known to think will be disagreeable to my uncle it will be such a triumph to the others',\n",
       "       'no no some time or other perhaps but not now he would mention no names now but such he could assure her had been the fact he had many years ago received such a description of miss anne elliot as had inspired him with the highest idea of her merit and excited the warmest curiosity to know her',\n",
       "       'i have frequently detected myself in such kind of mistakes said elinor in a total misapprehension of character in some point or other fancying people so much more gay or grave or ingenious or stupid than they really are and i can hardly tell why or in what the deception originated sometimes one is guided by what they say of themselves and very frequently by what other people say of them without giving oneself time to deliberate and judge'],\n",
       "      dtype='<U14176')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = int(data.shape[0] * .8)\n",
    "n_val = int(data.shape[0] * .2)\n",
    "\n",
    "indices = np.random.permutation(range(data.shape[0]))\n",
    "train_indices = indices[:n_train-n_val]\n",
    "val_indices = indices[n_train-n_val:n_train]\n",
    "test_indices = indices[n_train:]\n",
    "\n",
    "X_train, y_train = data[train_indices], labels[train_indices]\n",
    "X_val, y_val = data[val_indices], labels[val_indices]\n",
    "X_test, y_test = data[test_indices], labels[test_indices]\n",
    "\n",
    "assert X_train.shape[0] + X_val.shape[0] + X_test.shape[0] == n\n",
    "assert y_train.shape[0] + y_val.shape[0] + y_test.shape[0] == n\n",
    "\n",
    "X_train[20:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZls58QkMHq9",
    "outputId": "5fcab5d0-27a2-4d27-fe01-60f22a81ee71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2681"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = max(len(line.split()) for line in data)\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DPL-yoZnMkr2"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "seqs = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_pad = pad_sequences(seqs, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEaX3lqdb0NT",
    "outputId": "0a0de639-907f-433c-c16a-79f83ed3fcf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8441, 2681),\n",
       " array([[ 201,   13,   25, ...,    0,    0,    0],\n",
       "        [ 529,   14,   18, ...,    0,    0,    0],\n",
       "        [1788,   20,   10, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 530,  485,   15, ...,    0,    0,    0],\n",
       "        [  12,  169,    9, ...,    0,    0,    0],\n",
       "        [   1,  724,   55, ...,    0,    0,    0]], dtype=int32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape, X_train_pad[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J980IHl_aosP",
    "outputId": "404e0f34-938c-4fb5-c0ae-c18c83d86fe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2813, 2681), (2813, 2681))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = tokenizer.texts_to_sequences(X_val)\n",
    "X_val_pad = pad_sequences(seqs, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "seqs = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_pad = pad_sequences(seqs, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "X_val_pad.shape, X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FmLT2TKcBYU",
    "outputId": "2b160fb9-fa54-4e9f-9040-67dbe71c1311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-23 03:38:11--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-04-23 03:38:11--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-04-23 03:38:11--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip.1’\n",
      "\n",
      "glove.6B.zip.1      100%[===================>] 822.24M  5.06MB/s    in 2m 41s  \n",
      "\n",
      "2021-04-23 03:40:52 (5.11 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
      "\n",
      "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip -O /tmp/glove.6B.zip\n",
    "!unzip -q /tmp/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fn2tW6vdVDr",
    "outputId": "f7f168d6-1d50-4216-8fec-4c029ad7302c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(\"/tmp/glove.6B.100d.txt\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yf4-6G4fgBjq",
    "outputId": "296e71db-9c07-4ee5-c062-9b4d25a9f774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 16631 words (1185 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(tokenizer.word_index) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BN93KSCshenS",
    "outputId": "7aed73ae-f9e8-46b3-979a-48acc55b8346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2681, 100)         1781800   \n",
      "_________________________________________________________________\n",
      "zero_padding1d_1 (ZeroPaddin (None, 2687, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2684, 128)         51328     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 1,841,579\n",
      "Trainable params: 59,779\n",
      "Non-trainable params: 1,781,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Conv1D, ZeroPadding1D, Dense, GlobalMaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import Constant\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(\n",
    "    Embedding(\n",
    "        num_tokens,\n",
    "        embedding_dim,\n",
    "        embeddings_initializer=Constant(embedding_matrix),\n",
    "        trainable=False,\n",
    "        input_length=max_seq_length\n",
    "    )\n",
    ")\n",
    "cnn_model.add(ZeroPadding1D(3))\n",
    "cnn_model.add(Conv1D(128, 4, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(3, activation='softmax'))\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T44lWP4jwlTb",
    "outputId": "650702af-fd70-47f6-c89b-5fca8b205534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "264/264 [==============================] - 8s 26ms/step - loss: 0.0265 - acc: 0.9942 - precision_1: 0.9944 - recall_1: 0.9941 - val_loss: 0.4345 - val_acc: 0.9033 - val_precision_1: 0.9042 - val_recall_1: 0.9030\n",
      "Epoch 2/10\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0284 - acc: 0.9902 - precision_1: 0.9913 - recall_1: 0.9901 - val_loss: 0.2721 - val_acc: 0.9307 - val_precision_1: 0.9332 - val_recall_1: 0.9293\n",
      "Epoch 3/10\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0143 - acc: 0.9974 - precision_1: 0.9978 - recall_1: 0.9974 - val_loss: 0.2539 - val_acc: 0.9253 - val_precision_1: 0.9285 - val_recall_1: 0.9232\n",
      "Epoch 4/10\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0100 - acc: 0.9974 - precision_1: 0.9975 - recall_1: 0.9974 - val_loss: 0.2871 - val_acc: 0.9200 - val_precision_1: 0.9221 - val_recall_1: 0.9179\n",
      "Epoch 5/10\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0066 - acc: 0.9981 - precision_1: 0.9981 - recall_1: 0.9981 - val_loss: 0.2689 - val_acc: 0.9293 - val_precision_1: 0.9322 - val_recall_1: 0.9289\n",
      "Epoch 6/10\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0085 - acc: 0.9971 - precision_1: 0.9971 - recall_1: 0.9971 - val_loss: 0.3653 - val_acc: 0.9026 - val_precision_1: 0.9061 - val_recall_1: 0.8983\n",
      "Epoch 7/10\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0347 - acc: 0.9863 - precision_1: 0.9866 - recall_1: 0.9860 - val_loss: 0.3046 - val_acc: 0.9154 - val_precision_1: 0.9193 - val_recall_1: 0.9150\n",
      "Epoch 8/10\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0198 - acc: 0.9930 - precision_1: 0.9932 - recall_1: 0.9925 - val_loss: 0.3193 - val_acc: 0.9179 - val_precision_1: 0.9197 - val_recall_1: 0.9165\n",
      "Epoch 9/10\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0102 - acc: 0.9961 - precision_1: 0.9961 - recall_1: 0.9961 - val_loss: 0.3587 - val_acc: 0.9179 - val_precision_1: 0.9185 - val_recall_1: 0.9172\n",
      "Epoch 10/10\n",
      "264/264 [==============================] - 6s 24ms/step - loss: 0.0099 - acc: 0.9954 - precision_1: 0.9954 - recall_1: 0.9954 - val_loss: 0.3866 - val_acc: 0.9047 - val_precision_1: 0.9076 - val_recall_1: 0.9047\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import Precision, Recall\n",
    "from keras.optimizers import Adam\n",
    "cnn_model.compile(optimizer=Adam(lr=1E-3), loss='categorical_crossentropy', \n",
    "                  metrics=['acc', Precision(), Recall()])\n",
    "\n",
    "history = cnn_model.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val),\n",
    "                        batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_H3mKQDktQG",
    "outputId": "7070d62f-6099-43db-d590-22c1248f925e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 2681, 100)         1781800   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 2681, 256)         365568    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,180,651\n",
      "Trainable params: 398,851\n",
      "Non-trainable params: 1,781,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(\n",
    "        num_tokens,\n",
    "        embedding_dim,\n",
    "        embeddings_initializer=Constant(embedding_matrix),\n",
    "        trainable=False,\n",
    "        input_length=max_seq_length\n",
    "))\n",
    "lstm_model.add(LSTM(256, return_sequences=True))\n",
    "lstm_model.add(GlobalMaxPooling1D())\n",
    "lstm_model.add(Dense(128, activation='relu'))\n",
    "lstm_model.add(Dense(3, activation='softmax'))\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xD0ruqcM1nh3",
    "outputId": "1bb25fa2-5ec6-448c-bf27-e65d3465189c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "264/264 [==============================] - 46s 165ms/step - loss: 0.5868 - acc: 0.7620 - precision_2: 0.7940 - recall_2: 0.7112 - val_loss: 0.2354 - val_acc: 0.9062 - val_precision_2: 0.9284 - val_recall_2: 0.8891\n",
      "Epoch 2/10\n",
      "264/264 [==============================] - 42s 161ms/step - loss: 0.2025 - acc: 0.9233 - precision_2: 0.9395 - recall_2: 0.9098 - val_loss: 0.1883 - val_acc: 0.9239 - val_precision_2: 0.9366 - val_recall_2: 0.9133\n",
      "Epoch 3/10\n",
      "264/264 [==============================] - 43s 161ms/step - loss: 0.1400 - acc: 0.9474 - precision_2: 0.9570 - recall_2: 0.9397 - val_loss: 0.1719 - val_acc: 0.9328 - val_precision_2: 0.9403 - val_recall_2: 0.9243\n",
      "Epoch 4/10\n",
      "264/264 [==============================] - 42s 160ms/step - loss: 0.0902 - acc: 0.9675 - precision_2: 0.9728 - recall_2: 0.9627 - val_loss: 0.1890 - val_acc: 0.9307 - val_precision_2: 0.9346 - val_recall_2: 0.9250\n",
      "Epoch 5/10\n",
      "264/264 [==============================] - 42s 161ms/step - loss: 0.0570 - acc: 0.9814 - precision_2: 0.9836 - recall_2: 0.9798 - val_loss: 0.1826 - val_acc: 0.9339 - val_precision_2: 0.9384 - val_recall_2: 0.9307\n",
      "Epoch 6/10\n",
      "264/264 [==============================] - 42s 160ms/step - loss: 0.0296 - acc: 0.9925 - precision_2: 0.9929 - recall_2: 0.9916 - val_loss: 0.1720 - val_acc: 0.9325 - val_precision_2: 0.9365 - val_recall_2: 0.9285\n",
      "Epoch 7/10\n",
      "264/264 [==============================] - 42s 160ms/step - loss: 0.0198 - acc: 0.9961 - precision_2: 0.9961 - recall_2: 0.9957 - val_loss: 0.1898 - val_acc: 0.9385 - val_precision_2: 0.9400 - val_recall_2: 0.9360\n",
      "Epoch 8/10\n",
      "264/264 [==============================] - 42s 161ms/step - loss: 0.0185 - acc: 0.9960 - precision_2: 0.9965 - recall_2: 0.9953 - val_loss: 0.2089 - val_acc: 0.9371 - val_precision_2: 0.9398 - val_recall_2: 0.9328\n",
      "Epoch 9/10\n",
      "264/264 [==============================] - 42s 160ms/step - loss: 0.0161 - acc: 0.9967 - precision_2: 0.9967 - recall_2: 0.9967 - val_loss: 0.2131 - val_acc: 0.9399 - val_precision_2: 0.9411 - val_recall_2: 0.9378\n",
      "Epoch 10/10\n",
      "264/264 [==============================] - 42s 160ms/step - loss: 0.0127 - acc: 0.9968 - precision_2: 0.9968 - recall_2: 0.9968 - val_loss: 0.2009 - val_acc: 0.9396 - val_precision_2: 0.9425 - val_recall_2: 0.9381\n"
     ]
    }
   ],
   "source": [
    "lstm_model.compile(optimizer=Adam(lr=1E-3), loss='categorical_crossentropy', \n",
    "                  metrics=['acc', Precision(), Recall()])\n",
    "\n",
    "history = lstm_model.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val),\n",
    "                         batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbk74vnVldsV"
   },
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(\n",
    "        num_tokens,\n",
    "        embedding_dim,\n",
    "        embeddings_initializer=Constant(embedding_matrix),\n",
    "        trainable=False,\n",
    "        input_length=max_seq_length\n",
    "))\n",
    "lstm_model.add(LSTM(256, return_sequences=False))\n",
    "lstm_model.add(Dense(128, activation='relu'))\n",
    "lstm_model.add(Dense(3, activation='softmax'))\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer=Adam(lr=1E-3), loss='categorical_crossentropy', \n",
    "                  metrics=['acc', Precision(), Recall()])\n",
    "\n",
    "history = lstm_model.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val),\n",
    "                         batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8441, 17911), (2813, 17911), (2814, 17911))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def _insert_bias(X):\n",
    "    \"\"\" Inserts the bias \"\"\"\n",
    "    bias = np.ones((X.shape[0], 1))\n",
    "    if isinstance(X, scipy.sparse.csr.csr_matrix):\n",
    "        X = np.concatenate((X.todense(), bias), axis=1)  # Insert bias into the features\n",
    "        X = csr_matrix(X)\n",
    "    else:\n",
    "        X = np.concatenate((X, bias), axis=1)\n",
    "    return X\n",
    "\n",
    "vectorizer = TfidfVectorizer(vocabulary=tokenizer.word_index.keys())\n",
    "tf_train = vectorizer.fit_transform(X_train)\n",
    "tf_val = vectorizer.transform(X_val)\n",
    "tf_test = vectorizer.transform(X_test)\n",
    "\n",
    "assert tf_train.shape[0] + tf_val.shape[0] + tf_test.shape[0] == n\n",
    "\n",
    "tf_train.shape, tf_val.shape, tf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8441, 17912), (2813, 17912), (2814, 17912))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train = _insert_bias(tf_train)\n",
    "tf_val = _insert_bias(tf_val)\n",
    "tf_test = _insert_bias(tf_test)\n",
    "\n",
    "tf_train.shape, tf_val.shape, tf_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, learning_rate: float, max_epochs: int = 1000, precision: float = 1E-6, \n",
    "                 lam: float = 1E-4, optimizer: str = 'sgd', batch_size: int = None):\n",
    "        \"\"\" Initializes the class \"\"\"\n",
    "        self.rate = learning_rate\n",
    "        self.epochs = max_epochs\n",
    "        self.precision = precision\n",
    "        self.lambda_ = lam\n",
    "        self.b_ = batch_size\n",
    "        self.alg_ = self._set_optimizer(optimizer)\n",
    "        self.loss_ = None\n",
    "        self.val_loss_ = None\n",
    "        self.w_ = None\n",
    "        \n",
    "    def _set_optimizer(self, optimizer: str):\n",
    "        \"\"\" Sets the optimizer to either stochastic or mini-batch stochastic gradient descent \"\"\"\n",
    "        optimizer = optimizer.lower().strip()\n",
    "        if optimizer == 'sgd':\n",
    "            return self._stochastic_descent\n",
    "        elif optimizer == 'mbsgd':\n",
    "            if not self.b_:\n",
    "                raise ValueError(\"You must declare a batch size with 'batch_size' in order to use \" \\\n",
    "                                 \"mini-batch stochastic gradient descent\")\n",
    "            return self._mb_stochastic_descent\n",
    "        else:\n",
    "            raise ValueError(f\"Optimizer must be of value 'sgd' or 'mbsgd'. The value {optimizer} is not valid\")\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Predicts the class of the input array \"\"\"\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape((1, X.shape[0]))\n",
    "        phi = X.dot(self.w_)\n",
    "        return np.argmax(self._softmax_batch(phi), axis=1)\n",
    "    \n",
    "    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\" Scores how well the Logistic model predicts \"\"\"\n",
    "        labels = self.predict(X)\n",
    "        onehot = np.argmax(y, axis=1)\n",
    "        return sum(labels == onehot) / len(y)\n",
    "    \n",
    "    def plot(self) -> None:\n",
    "        \"\"\" Plots the loss \"\"\"\n",
    "        epochs = len(self.loss_)\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(epochs), self.loss_)\n",
    "        if self.val_loss_:\n",
    "            plt.plot(range(epochs), self.val_loss_)\n",
    "        plt.title('Loss per Epoch')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, X_val: np.ndarray = None, y_val: np.ndarray = None,\n",
    "            verbose: bool = True) -> None:\n",
    "        \"\"\" Fits the model to the training data \"\"\"\n",
    "        self.loss_ = list()\n",
    "        self.val_loss_ = list()\n",
    "        for i in range(self.epochs):\n",
    "            n, d = X.shape\n",
    "            rand_indices = np.random.permutation(n)\n",
    "            xi = X[rand_indices, :]\n",
    "            yi = y[rand_indices, :]\n",
    "            \n",
    "            if self.w_ is None:\n",
    "                self.w_ = np.random.normal(scale = 0.1, size = (d, yi.shape[1])) # d x k matrix\n",
    "            \n",
    "            loss = self.alg_(xi, yi)\n",
    "            self.loss_.append(loss)\n",
    "            \n",
    "            val_loss = None\n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_loss = self.loss(X_val, y_val)\n",
    "                self.val_loss_.append(val_loss)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Loss at epoch {i} is {loss}\")\n",
    "                if val_loss:\n",
    "                    print(f\"Val Loss at epoch {i} is {val_loss}\")\n",
    "            \n",
    "            if i > 0 and abs(self.loss_[i-1] - loss) <= self.precision:\n",
    "                print(f\"Precision reached at epoch {i}\")\n",
    "                break\n",
    "                \n",
    "            self.rate *= 0.9  # Decay the learning rate for stability\n",
    "            \n",
    "    def loss(self, X, y) -> float:\n",
    "        \"\"\" Defines the loss for the model \"\"\"\n",
    "        phi = X.dot(self.w_)  # 1 x k vector\n",
    "        softmax = self._softmax_batch(phi)  # 1 x k vector\n",
    "        loss = np.sum(np.multiply(y, np.log(softmax))) \n",
    "        loss += self.lambda_ * np.sum(np.square(self.w_))  # scalar\n",
    "        return -loss / X.shape[0]\n",
    "        \n",
    "    def _stochastic_descent(self, xi: np.ndarray, yi: np.ndarray) -> float:\n",
    "        \"\"\" Implementation of stochastic gradient descent \"\"\"\n",
    "        n, d = xi.shape\n",
    "        epoch_loss = 0.\n",
    "        for k in range(n):\n",
    "            x = xi[k, :]\n",
    "            y = yi[k, :]\n",
    "            loss, g = self._stochastic_gradient(x, y)\n",
    "            epoch_loss += loss\n",
    "            self.w_ -= self.rate * g\n",
    "        return -epoch_loss / n\n",
    "        \n",
    "    def _stochastic_gradient(self, x: np.ndarray, y: np.ndarray) -> Tuple[float, np.ndarray]:\n",
    "        \"\"\" Computes the stochastic gradient and its loss \"\"\"\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.reshape((1, x.shape[0]))  # 1 x d vector\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape((1, y.shape[0]))  # 1 x k vector\n",
    "        \n",
    "        phi = x.dot(self.w_)  # 1 x k vector\n",
    "        softmax = self._softmax(phi)  # 1 x k vector\n",
    "        loss = np.sum(np.multiply(y, np.log(softmax))) + (self.lambda_ * np.sum(np.square(self.w_)))  # scalar     \n",
    "        g = (x.T.dot(softmax - y)) + (2 * self.lambda_ * self.w_) # d x k matrix\n",
    "        return loss, g\n",
    "    \n",
    "    @staticmethod\n",
    "    def _softmax(phi: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Solves the softmax function \"\"\"\n",
    "        exps = np.exp(phi)\n",
    "        return exps / np.sum(exps)  # k x 1 matrix\n",
    "\n",
    "    def _mb_stochastic_descent(self, xi: np.ndarray, yi: np.ndarray) -> float:\n",
    "        \"\"\" Implementation of stochastic gradient descent \"\"\"\n",
    "        n, d = xi.shape\n",
    "        iters = int(n / self.b_)\n",
    "        epoch_loss = 0.\n",
    "        start = 0\n",
    "        for k in range(iters):\n",
    "            end = start + self.b_\n",
    "            x = xi[start:end, :]\n",
    "            y = yi[start:end, :]\n",
    "            loss, g = self._mb_stochastic_gradient(x, y)\n",
    "            epoch_loss += loss\n",
    "            self.w_ -= self.rate * g\n",
    "            start = end\n",
    "        return -epoch_loss / iters\n",
    "        \n",
    "    def _mb_stochastic_gradient(self, x: np.ndarray, y: np.ndarray) -> Tuple[float, np.ndarray]:\n",
    "        \"\"\" Computes the mini-batch stochastic gradient and its loss \"\"\"\n",
    "        phi = x.dot(self.w_)  # b x k matrix\n",
    "        softmax = self._softmax_batch(phi)  # b x k matrix\n",
    "        \n",
    "        loss = np.sum(np.multiply(y, np.log(softmax))) \n",
    "        loss += self.lambda_ * np.sum(np.square(self.w_))  # scalar\n",
    "        loss /= self.b_\n",
    "        \n",
    "        g = x.T.dot(softmax - y) + (2 * self.lambda_ * self.w_) # d x k matrix\n",
    "        g /= self.b_\n",
    "        return loss, g\n",
    "\n",
    "    @staticmethod\n",
    "    def _softmax_batch(phi: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Defines row-wise softmax \"\"\"\n",
    "        exps = np.exp(phi)\n",
    "        return exps / np.sum(exps, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 is 0.5381271068583384\n",
      "Val Loss at epoch 0 is 0.4620016999140597\n",
      "Loss at epoch 1 is 0.3279759629381678\n",
      "Val Loss at epoch 1 is 0.3905277350952977\n",
      "Loss at epoch 2 is 0.2559816981399501\n",
      "Val Loss at epoch 2 is 0.34946280369647614\n",
      "Loss at epoch 3 is 0.2174161007246965\n",
      "Val Loss at epoch 3 is 0.32821730057026394\n",
      "Loss at epoch 4 is 0.19426488756579702\n",
      "Val Loss at epoch 4 is 0.31933459365899397\n",
      "Loss at epoch 5 is 0.1787859943641449\n",
      "Val Loss at epoch 5 is 0.3134048712260651\n",
      "Loss at epoch 6 is 0.1679440398706021\n",
      "Val Loss at epoch 6 is 0.30782839861163286\n",
      "Loss at epoch 7 is 0.1600673799154562\n",
      "Val Loss at epoch 7 is 0.3030543065563039\n",
      "Loss at epoch 8 is 0.15449670434211038\n",
      "Val Loss at epoch 8 is 0.30741280343381017\n",
      "Loss at epoch 9 is 0.1500095134302906\n",
      "Val Loss at epoch 9 is 0.2985359206907214\n"
     ]
    }
   ],
   "source": [
    "sgdlog = LogisticRegression(0.1, max_epochs=10)\n",
    "sgdlog.fit(tf_train, y_train, tf_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgdlog.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the Neuron \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward(self, xi):\n",
    "        \"\"\" Defines the foward pass of the neuron \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def backward(self, xi, gradient, rate):\n",
    "        \"\"\" Defines the backward pass for the neuron \"\"\"\n",
    "        pass\n",
    "    \n",
    "\n",
    "class ReLU(Neuron):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the Neuron \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward(self, xi):\n",
    "        \"\"\" Defines the ReLU function \"\"\"\n",
    "        return np.maximum(0, xi)\n",
    "    \n",
    "    def backward(self, xi, gradient, rate):\n",
    "        \"\"\" Defines the gradient for the ReLU function \"\"\"\n",
    "        relu_g = xi > 0\n",
    "        backpass = gradient * relu_g\n",
    "        return backpass\n",
    "        \n",
    "\n",
    "class Tanh(Neuron):\n",
    "    \n",
    "    \"\"\" This was a thought, but it was not actually used \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the Neuron \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward(self, xi):\n",
    "        \"\"\" Defines the Tanh function \"\"\"\n",
    "        return np.tanh(xi)\n",
    "    \n",
    "    def backward(self, xi, gradient, rate):\n",
    "        \"\"\" Defines the gradient for the Tanh function \"\"\"\n",
    "        backpass = (1 - np.square(np.tanh(xi))) * gradient\n",
    "        return backpass\n",
    "    \n",
    "\n",
    "class Softmax(Neuron):\n",
    "     \n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the Neuron \"\"\"\n",
    "        pass\n",
    "\n",
    "    def forward(self, xi):\n",
    "        \"\"\" Defines the Softmax function \"\"\"\n",
    "        exps = np.exp(xi - np.max(xi))  # Adding np.max(xi) for numeric stability\n",
    "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "    \n",
    "    def backward(self, xi, gradient, rate):\n",
    "        \"\"\" Defines the gradient for the Softmax function \"\"\"\n",
    "        sm = self.forward(xi) \n",
    "        backpass = (sm - gradient) / xi.shape[0]  # Assume the gradient is one-hot encoded y\n",
    "        return backpass\n",
    "    \n",
    "\n",
    "class Layer(Neuron):\n",
    "    \n",
    "    def __init__(self, xdim: int, ydim: int):\n",
    "        \"\"\" Initializes the class \"\"\"\n",
    "        # Bias is assumed to be a feature for simplification purposes\n",
    "        self._he_init = np.sqrt((2 / (xdim + ydim)))  # Initialize the weights with He initialization scheme\n",
    "        self.w_ = np.random.normal(scale = self._he_init, size = (xdim, ydim))\n",
    "        \n",
    "    def forward(self, xi) -> np.ndarray:\n",
    "        \"\"\" Performs the linear matrix operation for the layer \"\"\"\n",
    "        return xi.dot(self.w_)\n",
    "    \n",
    "    def backward(self, xi, gradient, rate):\n",
    "        \"\"\" Performs the backward pass for the layer \"\"\"\n",
    "        # Mini-batch stochastic descent\n",
    "        cost = xi.T.dot(gradient) / xi.shape[0]  # Assumes mini-batch stochastic gradient-descent \n",
    "        self.w_ -= rate * cost\n",
    "        \n",
    "        # Gradient for Input\n",
    "        xi_gradient = gradient.dot(self.w_.T)\n",
    "        return xi_gradient\n",
    "    \n",
    "\n",
    "class Network:\n",
    "    \n",
    "    def __init__(self, learning_rate: float = 0.1, max_epochs: int = 1000, precision: float = 1E-6, \n",
    "                 batch_size: int = None):\n",
    "        \"\"\" Initializes the Network \"\"\"\n",
    "        self.network = []\n",
    "        self.rate = learning_rate\n",
    "        self.epochs = max_epochs\n",
    "        self.precision = precision\n",
    "        self.b_ = batch_size\n",
    "        self.loss_ = None\n",
    "        self.val_loss_ = None\n",
    "        self.get_loss = None\n",
    "        self.get_gradient = None\n",
    "    \n",
    "    def add_layer(self, layer) -> None:\n",
    "        \"\"\" Adds a layer to the network \"\"\"\n",
    "        self.network.append(layer)\n",
    "    \n",
    "    def loss(self, func, func_prime):\n",
    "        \"\"\" Sets the loss to use for the network \"\"\"\n",
    "        self.get_loss = func\n",
    "        self.get_gradient = func_prime\n",
    "            \n",
    "    def predict(self, X) -> np.ndarray:\n",
    "        \"\"\" Defines the predict function \"\"\"\n",
    "        results = self._feed_forward(X)\n",
    "        return results[-1]\n",
    "    \n",
    "    def score(self, X, y) -> float:\n",
    "        \"\"\" Scores the predictive ability of the Network \"\"\"\n",
    "        results = self.predict(X)\n",
    "        labels = np.argmax(results, axis=1)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        return sum(labels == y) / len(labels)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, X_val: np.ndarray = None, y_val: np.ndarray = None,\n",
    "            verbose: bool = True):\n",
    "        \"\"\" Fits the network to the training vectors \"\"\"\n",
    "        self.loss_ = list()\n",
    "        self.val_loss_ = list()\n",
    "        for i in range(self.epochs):\n",
    "            n, d = X.shape\n",
    "            rand_indices = np.random.permutation(n)\n",
    "            xi = X[rand_indices, :]\n",
    "            yi = y[rand_indices, :]\n",
    "            \n",
    "            loss = self._train(xi, yi)\n",
    "            self.loss_.append(loss)\n",
    "            \n",
    "            val_loss = None\n",
    "            if X_val is not None and y_val is not None:\n",
    "                preds = self.predict(X_val)\n",
    "                val_loss = -self.get_loss(preds, y_val)\n",
    "                self.val_loss_.append(val_loss)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Loss at epoch {i} is {loss}\")\n",
    "                if val_loss:\n",
    "                    print(f\"Val Loss at epoch {i} is {val_loss}\")\n",
    "            \n",
    "            if i > 0 and abs(self.loss_[i-1] - loss) <= self.precision:\n",
    "                print(f\"Precision reached at epoch {i}\")\n",
    "                break\n",
    "    \n",
    "    def plot(self) -> None:\n",
    "        \"\"\" Plots the loss \"\"\"\n",
    "        epochs = len(self.loss_)\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(epochs), self.loss_)\n",
    "        if self.val_loss_:\n",
    "            plt.plot(range(epochs), self.val_loss_)\n",
    "        plt.title('Loss per Epoch')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "    \n",
    "    def _train(self, xi: np.ndarray, yi: np.ndarray) -> float:\n",
    "        \"\"\" Implements mini-batch stochastic gradient descent \"\"\"\n",
    "        n, _ = xi.shape\n",
    "        iters = int(n / self.b_)\n",
    "        epoch_loss = 0.\n",
    "        start = 0\n",
    "        for k in range(iters):\n",
    "            end = start + self.b_\n",
    "            x = xi[start:end, :]\n",
    "            y = yi[start:end, :]\n",
    "            outputs = self._feed_forward(x)\n",
    "            result = outputs[-1]\n",
    "            \n",
    "            loss = self.get_loss(result, y)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            g = self.get_gradient(result, y)\n",
    "            self._backward_pass(outputs, g)\n",
    "            start = end\n",
    "        return -epoch_loss / iters\n",
    "        \n",
    "    def _feed_forward(self, xi) -> np.ndarray:\n",
    "        \"\"\" Feeds the sample forward through the network \"\"\"\n",
    "        outputs = [None] * (len(self.network) + 1)\n",
    "        outputs[0] = xi\n",
    "        for i, layer in enumerate(self.network):\n",
    "            xi = layer.forward(xi)\n",
    "            outputs[i + 1] = xi\n",
    "        return outputs\n",
    "    \n",
    "    def _backward_pass(self, outputs, gradient) -> None:\n",
    "        \"\"\" Implements a backward pass through the network \"\"\"\n",
    "        for i in range(len(outputs) - 1)[::-1]:\n",
    "            xi = outputs[i]\n",
    "            layer = self.network[i]\n",
    "            gradient = layer.backward(xi, gradient, self.rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(x, y) -> float:\n",
    "    \"\"\" Returns the loss of cross entropy logistic regression \"\"\"\n",
    "    loss = np.sum(np.multiply(y, np.log(x))) / x.shape[0]\n",
    "    return loss\n",
    "\n",
    "def cross_entropy_loss_g(x, y) -> np.ndarray:\n",
    "    \"\"\" Returns gradient of loss for network \"\"\"\n",
    "    return y  # Only return y because the output layer has the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(xdim: int, ydim: int, epochs: int = 30, batch_size = 12, neurons: int = 50) -> tuple:\n",
    "    \"\"\" Gets everything ready to start \"\"\"\n",
    "    net = Network(0.1, max_epochs = epochs, batch_size = batch_size)\n",
    "    net.add_layer(Layer(xdim, neurons))\n",
    "    net.add_layer(ReLU())\n",
    "    net.add_layer(Layer(neurons, ydim))\n",
    "    net.add_layer(Softmax())\n",
    "    net.loss(cross_entropy_loss, cross_entropy_loss_g)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 is 0.9418237528240301\n",
      "Val Loss at epoch 0 is 0.8839323100203551\n",
      "Loss at epoch 1 is 0.872758392846303\n",
      "Val Loss at epoch 1 is 0.8655237530753868\n",
      "Loss at epoch 2 is 0.8535588499856336\n",
      "Val Loss at epoch 2 is 0.8461091006498752\n",
      "Loss at epoch 3 is 0.8305360504634547\n",
      "Val Loss at epoch 3 is 0.8210466374672829\n",
      "Loss at epoch 4 is 0.800746205516205\n",
      "Val Loss at epoch 4 is 0.7891761984247779\n",
      "Loss at epoch 5 is 0.7640554951714409\n",
      "Val Loss at epoch 5 is 0.752190967986451\n",
      "Loss at epoch 6 is 0.7219802238239144\n",
      "Val Loss at epoch 6 is 0.7090944240972815\n",
      "Loss at epoch 7 is 0.6766879645042672\n",
      "Val Loss at epoch 7 is 0.6666751345868227\n",
      "Loss at epoch 8 is 0.6323948444739511\n",
      "Val Loss at epoch 8 is 0.6239586162224907\n",
      "Loss at epoch 9 is 0.5908145596885238\n",
      "Val Loss at epoch 9 is 0.586098019379832\n"
     ]
    }
   ],
   "source": [
    "net = build_network(tf_train.shape[1], y_train.shape[1], epochs = 10, neurons = 50)\n",
    "net.fit(tf_train, y_train, tf_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path: str):\n",
    "    \"\"\" Loads the file into memory \"\"\"\n",
    "    with open(path, 'r', encoding='ISO-8859-1') as fo:\n",
    "        content = fo.read()\n",
    "    return content\n",
    "\n",
    "def clean_data(lines: list):\n",
    "    \"\"\" Cleans the data for tokenization \"\"\"\n",
    "    cleaned = list()\n",
    "    for line in lines:\n",
    "        # Lowercase text and remove leading and ending newlines\n",
    "        line = line.lower().strip('\\n')\n",
    "        # Fix any encoding issues\n",
    "        line = normalize('NFD', line).encode('utf8')\n",
    "        line = line.decode('utf8')\n",
    "        # Remove new line symbols\n",
    "        line = line.replace('\\n', ' ')\n",
    "        # Remove special characters and numbers\n",
    "        line = re.sub(\"[^a-z\\s\\']+\", \" \", line).replace(\"'\", \"\")\n",
    "        # Remove whitespace\n",
    "        line = ' '.join(line.split())\n",
    "        cleaned.append(line)\n",
    "    return np.array(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_match = re.compile(r\"((?:\\<review_text\\>)([\\s\\w\\S]+?)(?:\\<\\/review_text\\>))\")\n",
    "\n",
    "pos = load_file('q2/positive.review')\n",
    "neg = load_file('q2/negative.review')\n",
    "pos_reviews = [r.group(2) for r in review_match.finditer(pos)]\n",
    "neg_reviews = [r.group(2) for r in review_match.finditer(neg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,\n",
       " 1000,\n",
       " [\"\\nBridget Jones, modern day woman, brillant and doesn't know it, prone to accidents and mess ups but manages to come out of them.  \\n\\nThis is the book that started it all with the chick lit fever.  Bridget Jones is my hero! \\n\",\n",
       "  \"\\nI am ordering copies for all 23 middle school principals and the two assistant principals leading two middle school programs in the Milwaukee Public Schools system. We will use Wheatley's book as the primary resource  for our professional growth at our MPS Middle School Principals  Collaborative institute August 9-11, 1999. We are not just concerned with  reform; we seek renewal as well. Wheatley provides the basis. She notes  that Einstein said that  a problem cannot be solved from the same  consciousness that created it. The entire book is a marvelous exploration  of this philosophy\\n\",\n",
       "  '\\nAs a casual piano player and a Broadway fanatic, I was so jazzed to play some of the songs from Avenue Q. The book contains everything you find on the CD and includes a few production photos.\\nOf course the little details are fun, using terms like \"manilowesque\" \"Huey-Lewis shuffle\" \"prissy sonata\" and \"funky a** groove\" to describe some of the songs. Fun fun fu\\n',\n",
       "  '\\nThis is one of the best biographies I have ever read. You can tell the authors put a lot of time and effort into this work - it\\'s a true labor of love. Filled with beautiful photos and extensive bibliographical notes, this one is a keeper. Who knew Miss Francis was such a \"wild child\"? Whether you\\'re a film scholar or a movie buff, Lynn Kear\\'s book deserves a special spot in your bookcase.\\n',\n",
       "  \"\\nI read this book many, many years ago on a very long flight.  I couldn't put it down.  The philosophy is simple; live frugally, save/invest money every month, and you too can be a millionaire.  It's great advice, especially in this day and age when the younger generation wants the big house, expensive car, and everything else right NOW, with no regard to the future.  Although some of the info is dated (Enron being named as a great company to invest), and some other advice (putting new soles on old shoes) is a bit much, the general message makes plenty of sense.\\n\"])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_reviews), len(neg_reviews), pos_reviews[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (1000,))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_cleaned = clean_data(pos_reviews)\n",
    "neg_cleaned = clean_data(neg_reviews)\n",
    "\n",
    "pos_labels = np.ones(len(pos_cleaned))\n",
    "neg_labels = np.zeros(len(neg_cleaned))\n",
    "\n",
    "pos_cleaned.shape, neg_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['in this book you get projects designs marked with skill levels needed for each project the projects are mostly made with wire but pearls are also used in most of the projects i would say that this is a book for you who has made jewelry before and are familiar to wirework if so it is a wonderful book this book offer lots and lots of inspirasjon and expertise',\n",
       "       'very topical easy read hope people in the know read this and give serious thought to the potential for something like this happening gives good reason why border control should be taken more serious by everybody looking forward to reading other books by mr bell',\n",
       "       'you dont have to be a fan of quot old quot hollywood to enjoy this wonderful book about a famous restaurant and its even more famous clientele fascinating stories accompanied by wonderful pictures this is only enhanced by the actual recipes of this great restaurant a wonderful coffee table book that will start conversations about movies movie stars and great food',\n",
       "       'ralph fletcher and joann portalupi have teamed up to create a book that is easy to understand and apply in the classroom setting the lessons can be adapted for all elementary grades and everything is spelled out for you as the teacher including the titles of books to use those familiar with the traits will find concrete examples to help develop each skill',\n",
       "       'i have just finished reading quot the power of ethical management quot and i thought it was well written in the past few weeks i have read several other books on business ethics and this one is my favorite it is short and exact with great details on how to improve your corporation as well as yourself this book not only can be applied to the work place but in your life at home family friends and children this book has helped me greatly'],\n",
       "      dtype='<U30325')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = int(pos_cleaned.shape[0] * .8)\n",
    "n_val = int(pos_cleaned.shape[0] * .2)\n",
    "\n",
    "indices = np.random.permutation(range(pos_cleaned.shape[0]))\n",
    "train_indices = indices[:n_train-n_val]\n",
    "val_indices = indices[n_train-n_val:n_train]\n",
    "test_indices = indices[n_train:]\n",
    "\n",
    "assert train_indices.shape[0] + val_indices.shape[0] + test_indices.shape[0] == 1000\n",
    "\n",
    "pos_train, y_pos_train = pos_cleaned[train_indices], pos_labels[train_indices]\n",
    "neg_train, y_neg_train = neg_cleaned[train_indices], neg_labels[train_indices]\n",
    "\n",
    "pos_val, y_pos_val = pos_cleaned[val_indices], pos_labels[val_indices]\n",
    "neg_val, y_neg_val = neg_cleaned[val_indices], neg_labels[val_indices]\n",
    "\n",
    "\n",
    "pos_test, y_pos_test = pos_cleaned[test_indices], pos_labels[test_indices]\n",
    "neg_test, y_neg_test = neg_cleaned[test_indices], neg_labels[test_indices]\n",
    "\n",
    "X_train[20:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['i was a little wary about the title but this was not at all about weight gain and or loss weight was incidental in this fiercely intelligent novel dorothy and justine are both desperately lonely women both victims of abuse and yet are different in other ways their parents often failed them their childhood was often full of shame and self sabotage but gaitskill writes this with complexity always aware that a victim can also be a victimizer gaitskill is never sentimental underneath her narrative underneath the pain and the sex scenes which are never fully loving and the disappointments and loneliness is a raging anger at the inability of human beings to connect on race on class but mostly on gender i sensed that anna granite the intellectual whose shadow dominates this narrative and who is the reason dorothy and justine first meet is gaitskills platform for displaying her keen intellect and sometimes there is a hint of didactism but this is a minor quibble the last section moved me very much and proved that although gaitskill abhors sentimentality she can certainly do sentiment well humanity is a word often found in this book our sexuality is connected to our humanity our ability to treat other human beings like human beings is what makes us human in the end gaitskills brilliant wonderfully feminist novel was for me about how easily we strip each other of our humanity',\n",
       "        'this book is very readable because it is oriented to the general reader chapter gives his short autobiography as to why he became an anthropologist and his experiences in kenya a forensic pathologist is a medical doctor trained in pathology a forensic anthropologist has a ph d and studied anthropology specializing in the human skeletal system chapter tells about his laboratory and the tools used for his work chapter has many of the cases he worked on chapter notes that most dismemberments result from the drug trade or motorcycle gangs the interstate highway system provides arteries for crimes and serial killers p chapter discusses cases of suicide many people kill themselves without intending to it is important to distinguish between murder and suicide p page tells why florida has an inordinate number of suicides chapter explains how forensic anthropology developed in response to murders this chapter discusses some famous cases of this relatively young science page tells how to distinguish between bone from rock by taste chapter says bones are not solid and unchanging they are constantly reshaping themselves in chapter maples tells of the use of capital punishment p and discusses the various methods pp he seems emotionally involved chapter informs us about cremation chapter has maples most difficult and most fascinating and perplexing case the two dead in high springs fl were linked to a shocking double murder in new hampshire p page jennings parents made a big fatal mistake in sending their daughter so far away after her failure as a freshman p chapter deals with the mia in vietnam about compared to the in korea hollywood movies created this popular image of captured men p a delusion p maples describes the us army central identification laboratory that identifies remains recovered from vietnam page tells what happened at the executive office building chapter tells of his investigation to recognize the skeleton of pizarro and correct an old mistake the exhumation of president zachary taylor and the tests for arsenic poisoning are told in chapter page tells of his importance to those times he backed free states in the new territories his replacement changed his policies chapter may be the most historically important maples was part of a team that identified the bones of tsar nicholas and his family maples draws political conclusions from rotten neglected teeth p chapter tells of the murder of five college students over two days in gainesville florida maples identified the murder weapon pp the book concludes with the complaint that states are not funding forensic anthropologists who are few and far between especially in florida pp florida is the most crime ridden state in the union that is a political decision for each state government this recalls the most realistic portion of quincy m e whenever quincy wanted to do more research his manager often said theres no money in the budget',\n",
       "        'dave barry has written and selected an extremely humorous collection of his articles from the miami herald there is a huge margin in difference of quality in boogers are my beat than in his initial non fiction books such as dave barrys bad habits boogers are my beat is one of those rare books that once you start turning the pages you dont want to put down until the back cover dave barry educates his fellow man on a diverse range of topics such as why you cant use the towels hanging in the bathroom the salt lake city olympics babies on airlines north dakota bear in the big blue house and cell phones to name just a few his article written the day after september and one written a year after about the philadelphia crashed plane are also included which prove barry could have been a serious writer if he had pursued that career thankfully he didnt because the rest of the book is hysterically funny as is his carl hiaasen style fiction novel tricky business big trouble isnt bad either check them out along with his other non fiction novels as well',\n",
       "        'we are in the last part of the th century in this novel and the wild west has breathed its last the book is peopled with real legends calamity jane buffalo bill sitting bull and fictional curiosities jim ragg and bartle bone two mountain men and no ears an indian with exceptional eyesight mcmurtry relates a sad elegiac farewell to times past the ever interesting characters and their views of the world which are wise and funny and fascinating make the novel top notch in the mcmurtry canon',\n",
       "        'firstly i have not seen the film adaptation of single white female and so this review isnt tainted one way or the other this book about the stolen identity of a young woman by her psychotic flatmate is written is very easy style characterizations prose and dialogue are all straightforward i can understand why a film was made based on it since the book reads more like a screenplay than a novel and the books feel is anything but original sliver by ira levin does a better job of capturing the essence of life and danger in manhattan for a single white female still single white female is an entertaining read bottom line a very enjoyable suspenseful read that doesnt tax the brain recommended'],\n",
       "       dtype='<U30325'),\n",
       " array([1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = np.hstack((pos_train, neg_train)), np.hstack((y_pos_train, y_neg_train))\n",
    "X_val, y_val = np.hstack((pos_val, neg_val)), np.hstack((y_pos_val, y_neg_val))\n",
    "X_test, y_test = np.hstack((pos_test, neg_test)), np.hstack((y_pos_test, y_neg_test))\n",
    "\n",
    "n = len(pos_cleaned) + len(neg_cleaned)\n",
    "print(X_train.shape[0] + X_val.shape[0] + X_test.shape[0])\n",
    "assert X_train.shape[0] + X_val.shape[0] + X_test.shape[0] == n\n",
    "assert y_train.shape[0] + y_val.shape[0] + y_test.shape[0] == n\n",
    "X_train[0:5], y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5355"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = max(len(line.split()) for line in data)\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "seqs = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_pad = pad_sequences(seqs, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 5355), (400, 5355))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = tokenizer.texts_to_sequences(X_val)\n",
    "X_val_pad = pad_sequences(seqs, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "seqs = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_pad = pad_sequences(seqs, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "X_val_pad.shape, X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(\"/tmp/glove.6B.100d.txt\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(tokenizer.word_index) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-e43782524505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m cnn_model.add(\n\u001b[1;32m      3\u001b[0m     Embedding(\n\u001b[1;32m      4\u001b[0m         \u001b[0mnum_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(\n",
    "    Embedding(\n",
    "        num_tokens,\n",
    "        embedding_dim,\n",
    "        embeddings_initializer=Constant(embedding_matrix),\n",
    "        trainable=False,\n",
    "        input_length=max_seq_length\n",
    "    )\n",
    ")\n",
    "cnn_model.add(ZeroPadding1D(3))\n",
    "cnn_model.add(Conv1D(128, 4, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(3, activation='softmax'))\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer=Adam(lr=1E-3), loss='binary_crossentropy', \n",
    "                  metrics=['acc'])\n",
    "\n",
    "history = cnn_model.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val),\n",
    "                        batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(\n",
    "        num_tokens,\n",
    "        embedding_dim,\n",
    "        embeddings_initializer=Constant(embedding_matrix),\n",
    "        trainable=False,\n",
    "        input_length=max_seq_length\n",
    "))\n",
    "lstm_model.add(LSTM(256, return_sequences=True))\n",
    "lstm_model.add(GlobalMaxPooling1D())\n",
    "lstm_model.add(Dense(128, activation='relu'))\n",
    "lstm_model.add(Dense(3, activation='softmax'))\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer=Adam(lr=1E-3), loss='binary_crossentropy', \n",
    "                  metrics=['acc'])\n",
    "\n",
    "history = lstm_model.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val),\n",
    "                         batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(\n",
    "        num_tokens,\n",
    "        embedding_dim,\n",
    "        embeddings_initializer=Constant(embedding_matrix),\n",
    "        trainable=False,\n",
    "        input_length=max_seq_length\n",
    "))\n",
    "lstm_model.add(LSTM(256, return_sequences=False))\n",
    "lstm_model.add(Dense(128, activation='relu'))\n",
    "lstm_model.add(Dense(3, activation='softmax'))\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer=Adam(lr=1E-3), loss='binary_crossentropy', \n",
    "                  metrics=['acc'])\n",
    "\n",
    "history = lstm_model.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val),\n",
    "                         batch_size=32, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
