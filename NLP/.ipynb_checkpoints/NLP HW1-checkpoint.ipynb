{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "from typing import Tuple\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may have to do this to get this project to run\n",
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1       3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2       3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3       3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4       3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', names=['target', 'text', 'description'])\n",
    "test = pd.read_csv('test.csv', names=['target', 'text', 'description'])\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data: pd.Series) -> pd.Series:\n",
    "    \"\"\" Performs the following actions:\n",
    "            1. Removes all punctionation\n",
    "            2. Removes stop words and common words\n",
    "            3. Removes symbols\n",
    "            4. Removes URLs\n",
    "            5. Remove numbers\n",
    "    \"\"\"\n",
    "    text = data\n",
    "    text = _remove_url(text)\n",
    "    text = _remove_non_chars(text)\n",
    "    text = _remove_stopwords(text)\n",
    "    return text\n",
    "    \n",
    "def _remove_url(column: pd.Series) -> pd.Series:\n",
    "    \"\"\" Removes all URLs from the data \"\"\"\n",
    "    url_match = re.compile(\"https?:\\/\\/\\S+\")\n",
    "    return column.apply(lambda x: re.sub(url_match, \" \", x))\n",
    "    \n",
    "def _remove_non_chars(column: pd.Series) -> pd.Series:\n",
    "    \"\"\" Removes all non-characters from the string, including punctionation and numbers \"\"\"\n",
    "    char_match = re.compile(\"[^a-z\\s\\']+\")\n",
    "    return column.apply(lambda x: re.sub(char_match, \" \", x.lower()).replace(\"'\", \"\"))\n",
    "\n",
    "def _remove_stopwords(column: pd.Series) -> pd.Series:\n",
    "    \"\"\" Removes stopwords \"\"\"\n",
    "    words = set(stopwords.words('english'))    \n",
    "    return column.apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>wall st bears claw back black reuters</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>carlyle looks toward commercial aerospace reuters</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>oil economy cloud stocks outlook reuters</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>iraq halts oil exports main southern pipeline ...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>oil prices soar time record posing new menace ...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       3              wall st bears claw back black reuters   \n",
       "1       3  carlyle looks toward commercial aerospace reuters   \n",
       "2       3           oil economy cloud stocks outlook reuters   \n",
       "3       3  iraq halts oil exports main southern pipeline ...   \n",
       "4       3  oil prices soar time record posing new menace ...   \n",
       "\n",
       "                                         description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'] = preprocess(train['text'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>fears n pension talks</td>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>race second private team sets launch date huma...</td>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ky company wins grant study peptides ap</td>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>prediction unit helps forecast wildfires ap</td>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>calif aims limit farm related smog ap</td>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       3                              fears n pension talks   \n",
       "1       4  race second private team sets launch date huma...   \n",
       "2       4            ky company wins grant study peptides ap   \n",
       "3       4        prediction unit helps forecast wildfires ap   \n",
       "4       4              calif aims limit farm related smog ap   \n",
       "\n",
       "                                         description  \n",
       "0  Unions representing workers at Turner   Newall...  \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...  \n",
       "2  AP - A company founded by a chemistry research...  \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...  \n",
       "4  AP - Southern California's smog-fighting agenc...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'] = preprocess(test['text'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_per_class(data: pd.DataFrame, group: str, col: str, per: int = 1100) -> set:\n",
    "    \"\"\" Gets the top per words from each class and returns the total vocab, in no particular order \"\"\"\n",
    "    vocab = set()\n",
    "    for group, frame in train.groupby(group):\n",
    "        class_vocab = []\n",
    "        [class_vocab.extend(word_tokenize(x)) for x in frame[col]]\n",
    "        freq = FreqDist(class_vocab)\n",
    "        vocab.update(sorted(freq, key=freq.get)[:per])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4271"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = get_top_per_class(train, 'target', 'text')\n",
    "len(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120000, 4271), (120000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=top)\n",
    "x_train = vectorizer.fit_transform(train['text'])\n",
    "y_train = np.array(train['target'])\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7600, 4271), (7600,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = vectorizer.transform(test['text'])\n",
    "y_test = np.array(test['target'])\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = set(vectorizer.get_feature_names())\n",
    "assert len(features - top) == 0  # No features outside the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Objective Function: $J (w; X, y) = -\\frac{1}{N} \\sum_{i=1}^n \\sum_{k=1}^k y_{ik} \\log \\Big( \\frac{\\exp(f_k)}{\\sum_c \\exp( f_c)} \\Big) + \\lambda \\| w \\|_2^2 $.\n",
    "\n",
    "Gradient: $\\frac{\\delta J}{\\delta w_k} = \\frac{1}{N} \\sum_{i=1}^n x_i \\Big(\\frac{\\exp(f_k)}{\\sum_c \\exp( f_c)} - y_i \\Big) + 2 \\lambda w_k $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, learning_rate: float, max_epochs: int = 1000, precision: float = 1E-6, \n",
    "                 lam: float = 1E-6, optimizer: str = 'sgd', batch_size: int = None):\n",
    "        \"\"\" Initializes the class \"\"\"\n",
    "        self.rate = learning_rate\n",
    "        self.epochs = max_epochs\n",
    "        self.precision = precision\n",
    "        self.lambda_ = lam\n",
    "        self.b_ = batch_size\n",
    "        self.alg_ = self._set_optimizer(optimizer)\n",
    "        self.loss_ = None\n",
    "        self.w_ = None\n",
    "        \n",
    "    def _set_optimizer(self, optimizer: str):\n",
    "        \"\"\" Sets the optimizer \"\"\"\n",
    "        optimizer = optimizer.lower().strip()\n",
    "        if optimizer == 'sgd':\n",
    "            return self._stochastic_descent\n",
    "        elif optimizer == 'mbsgd':\n",
    "            if not self.b_:\n",
    "                raise ValueError(\"You must declare a batch size with 'batch_size' in order to use \" \\\n",
    "                                 \"mini-batch stochastic gradient descent\")\n",
    "            return self._mb_stochastic_descent\n",
    "        else:\n",
    "            raise ValueError(f\"Optimizer must be of value 'sgd' or 'mbsgd'. The value {optimizer} is not valid\")\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Predicts the class of the input array \"\"\"\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape((1, X.shape[0]))\n",
    "        return np.argmax(self._softmax_batch(X.dot(self.w_)), axis=1)\n",
    "    \n",
    "    def score(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\" Scores how well the Logistic model predicts \"\"\"\n",
    "        correct = 0.0\n",
    "        X = self._insert_bias(X)\n",
    "        labels = self.predict(X)\n",
    "        for i, label in enumerate(labels):\n",
    "            correct += int(label == y[i])\n",
    "        return correct / len(y)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\" Fits the model to the training data \"\"\"\n",
    "        X, y = self._bootstrap(X, y)\n",
    "        self.loss_ = list()\n",
    "        for i in range(self.epochs):\n",
    "            n, d = X.shape\n",
    "            rand_indices = np.random.permutation(n)\n",
    "            xi = X[rand_indices, :]\n",
    "            yi = y[rand_indices, :]\n",
    "            \n",
    "            if self.w_ is None:\n",
    "                self.w_ = np.random.random((d, yi.shape[1]))  # d x k matrix\n",
    "            \n",
    "            loss = self.alg_(xi, yi)\n",
    "            self.loss_.append(loss)\n",
    "            \n",
    "            if i > 0 and abs(self.loss_[i-1] - loss) <= self.precision:\n",
    "                print(f\"Precision reached at epoch {i}\")\n",
    "                break\n",
    "                \n",
    "            self.rate *= 0.9\n",
    "            \n",
    "    def plot(self) -> None:\n",
    "        \"\"\" Plots the loss \"\"\"\n",
    "        epochs = len(self.loss_)\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(epochs), self.loss_)\n",
    "        plt.title('Loss per Epoch')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "    \n",
    "    def _bootstrap(self, X, y: np.ndarray) -> None:\n",
    "        \"\"\" Initializes a random weight and bias for the input data \"\"\"\n",
    "        X = self._insert_bias(X)  # Inserts the bias\n",
    "        y = self._one_hot(y)  # one hot encode the classes\n",
    "        return X, y\n",
    "    \n",
    "    @staticmethod\n",
    "    def _insert_bias(X):\n",
    "        \"\"\" Inserts the bias \"\"\"\n",
    "        bias = np.ones((X.shape[0], 1))\n",
    "        if isinstance(X, scipy.sparse.csr.csr_matrix):\n",
    "            X = np.concatenate((X.todense(), bias), axis=1)  # Insert bias into the features\n",
    "            X = csr_matrix(X)\n",
    "        else:\n",
    "            X = np.concatenate((X, bias), axis=1)\n",
    "        return X\n",
    "        \n",
    "    def _one_hot(self, y: np.ndarray)-> np.ndarray:\n",
    "        \"\"\" One hot encodes the targets \"\"\"\n",
    "        unique = sorted(np.unique(y))\n",
    "        onehot = np.zeros((y.shape[0], len(unique)))\n",
    "        for idx, val in enumerate(y):\n",
    "            cls_idx = unique.index(val)\n",
    "            onehot[idx][cls_idx] = 1\n",
    "        return onehot\n",
    "        \n",
    "    def _stochastic_descent(self, xi: np.ndarray, yi: np.ndarray) -> float:\n",
    "        \"\"\" Implementation of stochastic gradient descent \"\"\"\n",
    "        n, d = xi.shape\n",
    "        epoch_loss = 0.\n",
    "        for k in range(n):\n",
    "            x = xi[k, :]\n",
    "            y = yi[k, :]\n",
    "            loss, g = self._stochastic_gradient(x, y)\n",
    "            epoch_loss += loss\n",
    "            self.w_ -= self.rate * g\n",
    "        return -epoch_loss / n\n",
    "        \n",
    "    def _stochastic_gradient(self, x: np.ndarray, y: np.ndarray) -> Tuple[float, np.ndarray]:\n",
    "        \"\"\" Computes the stochastic gradient and its loss \"\"\"\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.reshape((1, x.shape[0]))  # 1 x d vector\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape((1, y.shape[0]))  # 1 x k vector\n",
    "        \n",
    "        phi = x.dot(self.w_)  # 1 x k vector\n",
    "        softmax = self._softmax(phi)  # 1 x k vector\n",
    "        loss = np.sum(np.multiply(y, np.log(softmax))) + (self.lambda_ * np.sum(np.square(self.w_)))  # scalar     \n",
    "        g = (x.T.dot(softmax - y)) + (2 * self.lambda_ * self.w_) # d x k matrix\n",
    "        return loss, g\n",
    "    \n",
    "    @staticmethod\n",
    "    def _softmax(phi: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Solves the softmax function \"\"\"\n",
    "        exps = np.exp(phi)\n",
    "        return exps / np.sum(exps)  # k x 1 matrix\n",
    "\n",
    "    def _mb_stochastic_descent(self, xi: np.ndarray, yi: np.ndarray) -> float:\n",
    "        \"\"\" Implementation of stochastic gradient descent \"\"\"\n",
    "        n, d = xi.shape\n",
    "        iters = int(n / self.b_)\n",
    "        epoch_loss = 0.\n",
    "        start = 0\n",
    "        for k in range(iters):\n",
    "            end = start + self.b_\n",
    "            x = xi[start:end, :]\n",
    "            y = yi[start:end, :]\n",
    "            loss, g = self._mb_stochastic_gradient(x, y)\n",
    "            epoch_loss += loss\n",
    "            self.w_ -= self.rate * g\n",
    "            start = end\n",
    "        return -epoch_loss / iters\n",
    "        \n",
    "    def _mb_stochastic_gradient(self, x: np.ndarray, y: np.ndarray) -> Tuple[float, np.ndarray]:\n",
    "        \"\"\" Computes the mini-batch stochastic gradient and its loss \"\"\"\n",
    "        phi = x.dot(self.w_)  # b x k matrix\n",
    "        softmax = self._softmax_batch(phi)  # b x k matrix\n",
    "        \n",
    "        loss = (1 / self.b_) * np.sum(np.multiply(y, np.log(softmax))) \n",
    "        loss += self.lambda_ * np.sum(np.square(self.w_))  # scalar\n",
    "        \n",
    "        g = (1 / self.b_) * ((x.T.dot(softmax - y)) + (2 * self.lambda_ * self.w_))\n",
    "        return loss, g\n",
    "\n",
    "    @staticmethod\n",
    "    def _softmax_batch(phi: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" Defines row-wise softmax \"\"\"\n",
    "        n, d = phi.shape\n",
    "        exps = np.exp(phi)\n",
    "        denom = (1 / np.sum(exps, axis=1)).reshape((n, 1))\n",
    "        return np.multiply(denom, exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision reached at epoch 77\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(0.1, optimizer='mbsgd', batch_size=50, max_epochs=100)\n",
    "log.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.21799166666666667, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.score(x_train, y_train), log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log2 = LogisticRegression(0.1, max_epochs=10)\n",
    "log2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.2186, None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log2.score(x_train, y_train), log2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron\n",
    "\n",
    "- One hidden layer with 50 neurons\n",
    "- 50 neurons are ReLU activiation functions\n",
    "\n",
    "Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the Neuron \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward(self, xi):\n",
    "        \"\"\" Defines the foward pass of the neuron \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def backward(self, xi, gradient, rate):\n",
    "        \"\"\" Defines the backward pass for the neuron \"\"\"\n",
    "        pass\n",
    "    \n",
    "\n",
    "class ReLU(Neuron):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the Neuron \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward(self, xi):\n",
    "        \"\"\" Defines the ReLU function \"\"\"\n",
    "        return np.maximum(0, xi)\n",
    "    \n",
    "    def backward(self, xi, gradient, rate):\n",
    "        \"\"\" Defines the gradient for the ReLU function \"\"\"\n",
    "        if xi > 0:\n",
    "            return gradient\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "\n",
    "class Tanh(Neuron):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the Neuron \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward(self, xi):\n",
    "        \"\"\" Defines the Tanh function \"\"\"\n",
    "        return np.tanh(xi)\n",
    "    \n",
    "    def backward(self, xi, gradient, rate):\n",
    "        \"\"\" Defines the gradient for the Tanh function \"\"\"\n",
    "        return (1 - np.square(np.tanh(xi))) * gradient\n",
    "\n",
    "\n",
    "class Softmax(Neuron):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the layer \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward(self, xi):\n",
    "        \"\"\" \"\"\"\n",
    "        n, _ = xi.shape\n",
    "        exps = np.exp(xi)\n",
    "        denom = (1 / np.sum(exps, axis=1)).reshape((n, 1))\n",
    "        return np.multiply(denom, exps)\n",
    "    \n",
    "    def backward(self, xi, gradient, rate):\n",
    "        \"\"\" Defines the gradient for the softmax function \"\"\"\n",
    "        n, _ = xi.shape\n",
    "        exps = np.exp(xi)\n",
    "        denom = (1 / np.sum(exps, axis=1)).reshape((n, 1))\n",
    "        return np.multiply(denom, exps) - gradient\n",
    "\n",
    "class Layer(Neuron):\n",
    "    \n",
    "    def __init__(self, xdim: int, ydim: int):\n",
    "        \"\"\" Initializes the class \"\"\"\n",
    "        self.w_ = np.random.random((xdim, ydim))  # Bias is assumed to be a feature for simplification purposes\n",
    "    \n",
    "    def forward(self, xi) -> np.ndarray:\n",
    "        \"\"\" Performs the linear matrix operation for the layer \"\"\"\n",
    "        return xi.dot(self.w_)\n",
    "    \n",
    "    def backward(self, xi, gradient, rate):\n",
    "        \"\"\" Performs the backward pass for the layer \"\"\"\n",
    "        # Stochastic descent\n",
    "        cost = xi.T.dot(gradient)\n",
    "        self.w_ -= rate * gradient\n",
    "        \n",
    "        # Gradient for Input\n",
    "        xi_gradient = gradient.dot(self.w_)\n",
    "        return xi_gradient\n",
    "    \n",
    "\n",
    "class Network:\n",
    "    \n",
    "    def __init__(self, learning_rate: float = 0.01, max_epochs: int = 1000, precision: float = 1E-6, \n",
    "                 batch_size: int = None):\n",
    "        \"\"\" Initializes the Network \"\"\"\n",
    "        self.network = []\n",
    "        self.rate = learning_rate\n",
    "        self.epochs = max_epochs\n",
    "        self.precision = precision\n",
    "        self.b_ = batch_size\n",
    "        self.loss_ = None\n",
    "        self.get_loss = None\n",
    "        self.get_gradient = None\n",
    "    \n",
    "    def add_layer(self, layer) -> None:\n",
    "        \"\"\" Adds a layer to the network \"\"\"\n",
    "        if hasattr(layer, 'rate'):\n",
    "            layer.rate = self.rate\n",
    "        self.network.append(layer)\n",
    "    \n",
    "    def loss(self, func, func_prime):\n",
    "        \"\"\" Sets the loss to use for the network \"\"\"\n",
    "        self.get_loss = func\n",
    "        self.get_gradient = func_prime\n",
    "            \n",
    "    def predict(self, X) -> list:\n",
    "        \"\"\" Defines the predict function \"\"\"\n",
    "        n, d = X.shape\n",
    "        results = list()\n",
    "        for i in range(n):\n",
    "            result = self._feed_forward(X[i, :])\n",
    "            results.append(result)\n",
    "        return results\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\" Fits the network to the training vectors \"\"\"\n",
    "        self.loss_ = list()\n",
    "        for i in range(self.epochs):\n",
    "            n, d = X.shape\n",
    "            rand_indices = np.random.permutation(n)\n",
    "            xi = X[rand_indices, :]\n",
    "            yi = y[rand_indices, :]\n",
    "            \n",
    "            loss = self._train(xi, yi)\n",
    "            self.loss_.append(loss)\n",
    "            \n",
    "            if i > 0 and abs(self.loss_[i-1] - loss) <= self.precision:\n",
    "                print(f\"Precision reached at epoch {i}\")\n",
    "                break\n",
    "                \n",
    "            self.rate *= 0.9\n",
    "    \n",
    "    def plot(self) -> None:\n",
    "        \"\"\" Plots the loss \"\"\"\n",
    "        epochs = len(self.loss_)\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(epochs), self.loss_)\n",
    "        plt.title('Loss per Epoch')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "    \n",
    "    def _train(self, xi: np.ndarray, yi: np.ndarray) -> float:\n",
    "        \"\"\" Implements stochastic gradient descent \"\"\"\n",
    "        n, _ = xi.shape\n",
    "        iters = int(n / self.b_)\n",
    "        epoch_loss = 0.\n",
    "        start = 0\n",
    "        for k in range(iters):\n",
    "            end = start + self.b_\n",
    "            x = xi[start:end, :]\n",
    "            y = yi[start:end, :]\n",
    "            result = self._feed_forward(x)\n",
    "            \n",
    "            loss = self.get_loss(result, y)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            g = self.get_gradient(result, y)\n",
    "            self._backward_pass(xi, g)\n",
    "            start = end\n",
    "        return -epoch_loss / iters\n",
    "        \n",
    "    def _feed_forward(self, xi):\n",
    "        \"\"\" Feeds the sample forward through the network \"\"\"\n",
    "        for layer in self.network:\n",
    "            xi = layer.forward(xi)\n",
    "        return xi\n",
    "    \n",
    "    def _backward_pass(self, xi, gradient) -> None:\n",
    "        \"\"\" Implements a backward pass through the network \"\"\"\n",
    "        for layer in self.network[::-1]:\n",
    "            layer.backward(xi, gradient, self.rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(x, y) -> float:\n",
    "    \"\"\" Returns the loss of cross entropy logistic regression \"\"\"\n",
    "    loss = (1 / x.shape[0]) * np.sum(np.multiply(y, np.log(x)))\n",
    "    return loss\n",
    "\n",
    "def loss_g(x, y) -> np.ndarray:\n",
    "    \"\"\" Returns gradient of loss for network \"\"\"\n",
    "    return y\n",
    "    \n",
    "def bootstrap(X, y) -> None:\n",
    "    \"\"\" Initializes a random weight and bias for the input data \"\"\"\n",
    "    X = _insert_bias(X)  # Inserts the bias\n",
    "    y = _one_hot(y)  # one hot encode the classes\n",
    "    return X, y\n",
    "    \n",
    "def _insert_bias(X):\n",
    "    \"\"\" Inserts the bias \"\"\"\n",
    "    bias = np.ones((X.shape[0], 1))\n",
    "    if isinstance(X, scipy.sparse.csr.csr_matrix):\n",
    "        X = np.concatenate((X.todense(), bias), axis=1)  # Insert bias into the features\n",
    "        X = csr_matrix(X)\n",
    "    else:\n",
    "        X = np.concatenate((X, bias), axis=1)\n",
    "    return X\n",
    "\n",
    "def _one_hot(y: np.ndarray)-> np.ndarray:\n",
    "    \"\"\" One hot encodes the targets \"\"\"\n",
    "    unique = sorted(np.unique(y))\n",
    "    onehot = np.zeros((y.shape[0], len(unique)))\n",
    "    for idx, val in enumerate(y):\n",
    "        cls_idx = unique.index(val)\n",
    "        onehot[idx][cls_idx] = 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 10))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# load MNIST from server\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# training data : 60000 samples\n",
    "# reshape and normalize input data\n",
    "x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "# encode output which is a number in range [0,9] into a vector of size 10\n",
    "# e.g. number 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "# same for test data : 10000 samples\n",
    "x_test = x_test.reshape(x_test.shape[0], 28 * 28)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 10\n",
    "n, d = x_train.shape\n",
    "net = Network(max_epochs=10, batch_size = 10)\n",
    "net.add_layer(Layer(d, 50))\n",
    "net.add_layer(ReLU())\n",
    "net.add_layer(Layer(50, 1))\n",
    "net.add_layer(Softmax())\n",
    "net.loss(loss, loss_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-ef324f00975b>:58: RuntimeWarning: overflow encountered in exp\n",
      "  exps = np.exp(xi)\n",
      "<ipython-input-41-ef324f00975b>:60: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.multiply(denom, exps)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (50,1) (10,10) (50,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-2af387b44e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-ef324f00975b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0myi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-ef324f00975b>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, xi, yi)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-ef324f00975b>\u001b[0m in \u001b[0;36m_backward_pass\u001b[0;34m(self, xi, gradient)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;34m\"\"\" Implements a backward pass through the network \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-ef324f00975b>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, xi, gradient, rate)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Stochastic descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Gradient for Input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (50,1) (10,10) (50,1) "
     ]
    }
   ],
   "source": [
    "net.fit(x_train[0:1000], y_train[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
